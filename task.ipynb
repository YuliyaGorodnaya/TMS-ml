{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5ac751c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f233964c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import GPT2Tokenizer, T5ForConditionalGeneration, AutoTokenizer, T5Tokenizer, AutoModelForSeq2SeqLM, AutoModelForCausalLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26e6f848",
   "metadata": {},
   "outputs": [],
   "source": [
    "summarizer = pipeline(\"summarization\", model=\"facebook/bart-large-cnn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "83e0cc9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ARTICLE_1 = \"\"\"\n",
    "    China on Monday announced tariffs of up to 42.7% on dairy products from the European Union, following the results of an anti-subsidy investigation that began in August 2024.\n",
    "    In a statement by the country's Ministry of Commerce, China said that EU subsidies for dairy products had caused \"substantial damage\" to China's domestic dairy industries.\n",
    "    The tariffs are set to take effect on Dec. 23, the ministry said, and the rates would be determined by the amount of \"ad valorem subsidy rates\" from the country's Customs Tariff Commission.\n",
    "    The tariffs range from 21.9% to 42.7%, with companies \"who cooperated with the investigation\" subject to tariffs of 28.6%, and those that \"did not cooperate\" facing the top rate of 42.7%, according to a statement from a Commerce Ministry official.\n",
    "    Products that will be affected include fresh, processed and blue cheeses — such as the famous Roquefort blue cheese aged in the caves of Roquefort-sur-Soulzon, France — as well as some kinds of milk and cream.\n",
    "    The latest tariffs mark an escalation in trade tensions between the regions, which flared up when Brussels slapped tariffs of up to 45% on electric vehicles imported from China in October last year.\n",
    "    Separately, the bloc in November challenged China's imposition of tariffs on imports of EU brandy at the World Trade Organisation, saying \"China's provisional measures on EU brandy are not in line with WTO rules.\"\n",
    "    An EU spokesperson described the measures as \"unjustified and unwarranted\" on Monday, according to Reuters, and said the European Commission, the EU's executive arm, would be providing comments to the Chinese authorities.\n",
    "    The Commission was not immediately available to comment when contacted by CNBC Monday.\n",
    "    Last week, Beijing sharply cut its duties on pork imports and pig by-products from the European Union, with new tariff rates ranging from 4.9% to 19.8% on dozens of European pork exports.\n",
    "    It comes after the country in September imposed temporary anti-dumping tariffs of up to 62.4% in the form of cash deposits on pork imports from the EU.\n",
    "    — CNBC's Anniek Bao contributed to this report.\n",
    "    Correction: This article has been updated to reflect that China's tariffs will come into force on Dec. 23.\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "faf1a546",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_1 = summarizer(ARTICLE_1, max_length=130, min_length=30, do_sample=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ee9c9434",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'summary_text': 'China announces tariffs of up to 42.7% on dairy products from the European Union. The move follows an anti-subsidy investigation that began in August 2024. Products affected include fresh, processed and blue cheeses, as well as milk and cream.'}]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8efb0488",
   "metadata": {},
   "outputs": [],
   "source": [
    "ARTICLE_2 = \"\"\"\n",
    "Once there lived an old man and old woman. The old man said, «Old woman, bake me a bun.» «What can I make it from? I have no flour.» «Eh, eh, old woman! Scrape the cupboard, sweep the flour bin, and you will find enough flour.» The old woman picked up a duster, scraped the cupboard, swept the flour bin and gathered about two handfuls of flour.\n",
    "She mixed the dough with sour cream, fried it in butter, and put the bun on the window sill to cool. The bun lay and lay there. Suddenly it rolled off the window sill to the bench, from the bench to the floor, from the floor to the door. Then it rolled over the threshold to the entrance hall, from the entrance hall to the porch, from the porch to the courtyard, from the courtyard trough the gate and on and on.\n",
    "The bun rolled along the road and met a hare. «Little bun, little bun, I shall eat you up!» said the hare. «Don’t eat me, slant-eyed hare! I will sing you a song,» said the bun, and sang: I was scraped from the cupboard, Swept from the bin, Kneaded with sour cream, Fried in butter, And coolled on the sill. I got away from Grandpa, I got away from Grandma And I’ll get away from you, hare! And the bun rolled away before the hare even saw it move!\n",
    "The bun rolled on and met a wolf. «Little bun, little bun, I shall eat you up,» said the wolf. «Don’t eat me, gray wolf!» said the bun. «I will sing you a song.» And the bun sang: I was scraped from the cupboard, Swept from the bin, Kneaded with sour cream, Fried in butter, And coolled on the sill. I got away from Grandpa, I got away from Grandma I got away from the hare, And I’ll get away from you, gray wolf! And the bun rolled away before the wolf even saw it move!\n",
    "The bun rolled on and met a bear. «Little bun, little bun, I shall eat you up,» the bear said. «You will not, pigeon toes!» And the bun sang: I was scraped from the cupboard, Swept from the bin, Kneaded with sour cream, Fried in butter, And coolled on the sill. I got away from Grandpa, I got away from Grandma I got away from the hare, I got away from the wolf, And I’ll get away from you, big bear! And again the bun rolled away before the bear even saw it move!\n",
    "The bun rolled and rolled and met a fox. «Hello, little bun, how nice yor are!» said the fox. And the bun sang: I was scraped from the cupboard, Swept from the bin, Kneaded with sour cream, Fried in butter, And coolled on the sill. I got away from Grandpa, I got away from Grandma, I got away from the hare, I got away from the wolf, I got away from bear, And I’ll get away from you, old fox!\n",
    "«What a wonderful song!» said the fox. «But little bun, I have became old now and hard of hearing. Come sit on my snout and sing your song again a little louder.» The bun jumped up on the fox’s snout and sang the same song. «Thank you, little bun, that was a wonderful song. I’d like to hear it again. Come sit on my tongue and sing it for the last time,» said the fox, sticking out her tongue. The bun foolishly jumped onto her tongue and- snatch!- she ate it.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "899766cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_2 = summarizer(ARTICLE_2, max_length=130, min_length=30, do_sample=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f704ab39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'summary_text': 'Once there lived an old man and old woman. The bun lay and lay there. Suddenly it rolled off the window sill to the bench, from the bench to the floor. Then it rolled over the threshold to the entrance hall. And the bun sang: I was scraped from the cupboard.'}]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3401bdfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    }
   ],
   "source": [
    "summarizer_2 = pipeline(\"summarization\", model=\"Falconsai/text_summarization\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b1e61ac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "ARTICLE_3 = \"\"\"\n",
    "The artificial intelligence models that turn text into images are also useful for generating new materials. Over the last few years, generative materials models from companies like Google, Microsoft, and Meta have drawn on their training data to help researchers design tens of millions of new materials.\n",
    "But when it comes to designing materials with exotic quantum properties like superconductivity or unique magnetic states, those models struggle. That’s too bad, because humans could use the help. For example, after a decade of research into a class of materials that could revolutionize quantum computing, called quantum spin liquids, only a dozen material candidates have been identified. The bottleneck means there are fewer materials to serve as the basis for technological breakthroughs.\n",
    "Now, MIT researchers have developed a technique that lets popular generative materials models create promising quantum materials by following specific design rules. The rules, or constraints, steer models to create materials with unique structures that give rise to quantum properties.\n",
    "“The models from these large companies generate materials optimized for stability,” says Mingda Li, MIT’s Class of 1947 Career Development Professor. “Our perspective is that’s not usually how materials science advances. We don’t need 10 million new materials to change the world. We just need one really good material.”\n",
    "The approach is described today in a paper published by Nature Materials. The researchers applied their technique to generate millions of candidate materials consisting of geometric lattice structures associated with quantum properties. From that pool, they synthesized two actual materials with exotic magnetic traits.\n",
    "“People in the quantum community really care about these geometric constraints, like the Kagome lattices that are two overlapping, upside-down triangles. We created materials with Kagome lattices because those materials can mimic the behavior of rare earth elements, so they are of high technical importance.” Li says.\n",
    "Li is the senior author of the paper. His MIT co-authors include PhD students Ryotaro Okabe, Mouyang Cheng, Abhijatmedhi Chotrattanapituk, and Denisse Cordova Carrizales; postdoc Manasi Mandal; undergraduate researchers Kiran Mak and Bowen Yu; visiting scholar Nguyen Tuan Hung; Xiang Fu ’22, PhD ’24; and professor of electrical engineering and computer science Tommi Jaakkola, who is an affiliate of the Computer Science and Artificial Intelligence Laboratory (CSAIL) and Institute for Data, Systems, and Society. Additional co-authors include Yao Wang of Emory University, Weiwei Xie of Michigan State University, YQ Cheng of Oak Ridge National Laboratory, and Robert Cava of Princeton University.\n",
    "Steering models toward impact\n",
    "A material’s properties are determined by its structure, and quantum materials are no different. Certain atomic structures are more likely to give rise to exotic quantum properties than others. For instance, square lattices can serve as a platform for high-temperature superconductors, while other shapes known as Kagome and Lieb lattices can support the creation of materials that could be useful for quantum computing.\n",
    "To help a popular class of generative models known as a diffusion models produce materials that conform to particular geometric patterns, the researchers created SCIGEN (short for Structural Constraint Integration in GENerative model). SCIGEN is a computer code that ensures diffusion models adhere to user-defined constraints at each iterative generation step. With SCIGEN, users can give any generative AI diffusion model geometric structural rules to follow as it generates materials.\n",
    "AI diffusion models work by sampling from their training dataset to generate structures that reflect the distribution of structures found in the dataset. SCIGEN blocks generations that don’t align with the structural rules.\n",
    "To test SCIGEN, the researchers applied it to a popular AI materials generation model known as DiffCSP. They had the SCIGEN-equipped model generate materials with unique geometric patterns known as Archimedean lattices, which are collections of 2D lattice tilings of different polygons. Archimedean lattices can lead to a range of quantum phenomena and have been the focus of much research.\n",
    "“Archimedean lattices give rise to quantum spin liquids and so-called flat bands, which can mimic the properties of rare earths without rare earth elements, so they are extremely important,” says Cheng, a co-corresponding author of the work. “Other Archimedean lattice materials have large pores that could be used for carbon capture and other applications, so it’s a collection of special materials. In some cases, there are no known materials with that lattice, so I think it will be really interesting to find the first material that fits in that lattice.”\n",
    "The model generated over 10 million material candidates with Archimedean lattices. One million of those materials survived a screening for stability. Using the supercomputers in Oak Ridge National Laboratory, the researchers then took a smaller sample of 26,000 materials and ran detailed simulations to understand how the materials’ underlying atoms behaved. The researchers found magnetism in 41 percent of those structures.\n",
    "From that subset, the researchers synthesized two previously undiscovered compounds, TiPdBi and TiPbSb, at Xie and Cava’s labs. Subsequent experiments showed the AI model’s predictions largely aligned with the actual material’s properties.\n",
    "“We wanted to discover new materials that could have a huge potential impact by incorporating these structures that have been known to give rise to quantum properties,” says Okabe, the paper’s first author. “We already know that these materials with specific geometric patterns are interesting, so it’s natural to start with them.”\n",
    "Accelerating material breakthroughs\n",
    "Quantum spin liquids could unlock quantum computing by enabling stable, error-resistant qubits that serve as the basis of quantum operations. But no quantum spin liquid materials have been confirmed. Xie and Cava believe SCIGEN could accelerate the search for these materials.\n",
    "“There’s a big search for quantum computer materials and topological superconductors, and these are all related to the geometric patterns of materials,” Xie says. “But experimental progress has been very, very slow,” Cava adds. “Many of these quantum spin liquid materials are subject to constraints: They have to be in a triangular lattice or a Kagome lattice. If the materials satisfy those constraints, the quantum researchers get excited; it’s a necessary but not sufficient condition. So, by generating many, many materials like that, it immediately gives experimentalists hundreds or thousands more candidates to play with to accelerate quantum computer materials research.”\n",
    "“This work presents a new tool, leveraging machine learning, that can predict which materials will have specific elements in a desired geometric pattern,” says Drexel University Professor Steve May, who was not involved in the research. “This should speed up the development of previously unexplored materials for applications in next-generation electronic, magnetic, or optical technologies.”\n",
    "The researchers stress that experimentation is still critical to assess whether AI-generated materials can be synthesized and how their actual properties compare with model predictions. Future work on SCIGEN could incorporate additional design rules into generative models, including chemical and functional constraints.\n",
    "“People who want to change the world care about material properties more than the stability and structure of materials,” Okabe says. “With our approach, the ratio of stable materials goes down, but it opens the door to generate a whole bunch of promising materials.”\n",
    "The work was supported, in part, by the U.S. Department of Energy, the National Energy Research Scientific Computing Center, the National Science Foundation, and Oak Ridge National Laboratory.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eb914016",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1710 > 512). Running this sequence through the model will result in indexing errors\n",
      "Both `max_new_tokens` (=256) and `max_length`(=130) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    }
   ],
   "source": [
    "summary_3 = summarizer_2(ARTICLE_3, max_length=130, min_length=30, do_sample=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "39373d26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'summary_text': 'In recent years, generative materials models from companies like Google, Microsoft, and Meta have drawn on their training data to help researchers design tens of millions of new materials . But when it comes to designing materials with exotic quantum properties, those models struggle . For example, after a decade of research into a class of materials that could revolutionize quantum computing, called quantum spin liquids, only a dozen material candidates have been identified .'}]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9ad8955e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    }
   ],
   "source": [
    "summarizer_3 = pipeline(\"summarization\", model=\"Callidior/bert2bert-base-arxiv-titlegen\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0396d151",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_4 = summarizer_3(ARTICLE_1, max_length=130, min_length=30, do_sample=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a0b2e703",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'summary_text': 'how to deal with the cyberscience of china \\' s api? a correction of a report on \" fair and unwarranted assessments on the'}]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary_4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "143a95b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "ARTICLE_3_1 = \"\"\"\n",
    "The artificial intelligence models that turn text into images are also useful for generating new materials. Over the last few years, generative materials models from companies like Google, Microsoft, and Meta have drawn on their training data to help researchers design tens of millions of new materials.\n",
    "But when it comes to designing materials with exotic quantum properties like superconductivity or unique magnetic states, those models struggle. That’s too bad, because humans could use the help. For example, after a decade of research into a class of materials that could revolutionize quantum computing, called quantum spin liquids, only a dozen material candidates have been identified. The bottleneck means there are fewer materials to serve as the basis for technological breakthroughs.\n",
    "Now, MIT researchers have developed a technique that lets popular generative materials models create promising quantum materials by following specific design rules. The rules, or constraints, steer models to create materials with unique structures that give rise to quantum properties.\n",
    "“The models from these large companies generate materials optimized for stability,” says Mingda Li, MIT’s Class of 1947 Career Development Professor. “Our perspective is that’s not usually how materials science advances. We don’t need 10 million new materials to change the world. We just need one really good material.”\n",
    "The approach is described today in a paper published by Nature Materials. The researchers applied their technique to generate millions of candidate materials consisting of geometric lattice structures associated with quantum properties. From that pool, they synthesized two actual materials with exotic magnetic traits.\n",
    "“People in the quantum community really care about these geometric constraints, like the Kagome lattices that are two overlapping, upside-down triangles. We created materials with Kagome lattices because those materials can mimic the behavior of rare earth elements, so they are of high technical importance.” Li says.\n",
    "Li is the senior author of the paper.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "af73d196",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_5 = summarizer_3(ARTICLE_3_1, max_length=130, min_length=30, do_sample=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d31dc816",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'summary_text': \"materials with kagome lattices can change the world ' s materials that can be change. or, that is the essence of materials who is next\"}]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary_5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab97a4d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "summarizer_4 = pipeline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9d5e8bc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching 2 files:   0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCannot execute code, session has been disposed. Please try restarting the Kernel."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCannot execute code, session has been disposed. Please try restarting the Kernel. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "tokenizer = GPT2Tokenizer.from_pretrained('RussianNLP/FRED-T5-Summarizer',eos_token='</s>')\n",
    "model = T5ForConditionalGeneration.from_pretrained('RussianNLP/FRED-T5-Summarizer')\n",
    "device='cuda'\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "02ac6f78",
   "metadata": {},
   "outputs": [],
   "source": [
    "ARTICLE_4 = \"\"\"\n",
    "Жили-были старик со старухой. Однажды просит старик:\n",
    "Дедушка и бабушка\n",
    "— Испеки, старуха, колобок.\n",
    "— Из чего испечь-то? Муки нет.\n",
    "— Эх, старуха! По коробу поскреби, по сусеку помети; авось муки и наберется.\n",
    "Старуха по коробу поскребла, по сусеку помела, и набралось муки две пригоршни. Замесила на сметане, пожарила в масле и положила на окошечко остудить.\n",
    "Колобок полежал-полежал, да вдруг и покатился — с окна на лавку, с лавки на пол, по полу да к дверям, перепрыгнул через порог в сени, из сеней на крыльцо, с крыльца на двор, со двора за ворота, дальше и дальше.\n",
    "Катится колобок по дороге, а навстречу ему заяц:\n",
    "— Колобок, колобок! Я тебя съем!\n",
    "— Не ешь меня, косой зайчик! Я тебе песенку спою, — сказал колобок и запел:\n",
    "Я по коробу скребен,\n",
    "По сусеку метен,\n",
    "На сметане мешон\n",
    "Да в масле пряжон,\n",
    "На окошке стужон;\n",
    "Я от дедушки ушел,\n",
    "Я от бабушки ушел,\n",
    "От тебя, зайца, не хитро уйти!\n",
    "И покатился себе дальше; только заяц его и видел!..\n",
    "Катится колобок, а навстречу ему волк:\n",
    "— Колобок, колобок! Я тебя съем!\n",
    "— Не ешь меня, серый волк! Я тебе песенку спою!\n",
    "Я по коробу скребен,\n",
    "По сусеку метен,\n",
    "На сметане мешон\n",
    "Да в масле пряжон,\n",
    "На окошке стужон;\n",
    "Я от дедушки ушел,\n",
    "Я от бабушки ушел,\n",
    "Я от зайца ушел,\n",
    "От тебя, волка, не хитро уйти!\n",
    "И покатился себе дальше; только волк его и видел!..\n",
    "Катится колобок, а навстречу ему медведь:\n",
    "— Колобок, колобок! Я тебя съем.\n",
    "— Где тебе, косолапому, съесть меня!\n",
    "Я по коробу скребен,\n",
    "По сусеку метен,\n",
    "На сметане мешон\n",
    "Да в масле пряжон,\n",
    "На окошке стужон;\n",
    "Я от дедушки ушел,\n",
    "Я от бабушки ушел,\n",
    "Я от зайца ушел,\n",
    "Я от волка ушел,\n",
    "От тебя, медведь, не хитро уйти!\n",
    "И опять укатился; только медведь его и видел!..\n",
    "Катится, катится колобок, а навстречу ему лиса:\n",
    "Лисичка\n",
    "— Здравствуй, колобок! Какой ты хорошенький!\n",
    "А колобок запел:\n",
    "Я по коробу скребен,\n",
    "По сусеку метен,\n",
    "На сметане мешон\n",
    "Да в масле пряжон,\n",
    "На окошке стужон;\n",
    "Я от дедушки ушел,\n",
    "Я от бабушки ушел,\n",
    "Я от зайца ушел,\n",
    "Я от волка ушел,\n",
    "От медведя ушел,\n",
    "От тебя, лиса, и подавно уйду!\n",
    "— Какая славная песенка! — сказала лиса. — Но ведь я, колобок, стара стала, плохо слышу; сядь-ка на мою мордочку да пропой еще разок погромче.\n",
    "Колобок вскочил лисе на мордочку и запел ту же песню.\n",
    "Колобок на носу у лисички\n",
    "— Спасибо, колобок! Славная песенка, еще бы послушала! Сядь-ка на мой язычок да пропой в последний разок, — сказала лиса и высунула свой язык.\n",
    "Колобок прыг ей на язык, а лиса — ам его! — и скушала.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8f3bc716",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Колобок, а навстречу ему медведь, волк и серый волк — что испечь, старуха, чтобы съесть его, сказал старик и запел: «Не ешь меня, косой зайчик, я тебе песенку спою».'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_name = \"IlyaGusev/rut5_base_sum_gazeta\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = T5ForConditionalGeneration.from_pretrained(model_name)\n",
    "\n",
    "input_ids = tokenizer(\n",
    "    [ARTICLE_4],\n",
    "    max_length=600,\n",
    "    add_special_tokens=True,\n",
    "    padding=\"max_length\",\n",
    "    truncation=True,\n",
    "    return_tensors=\"pt\"\n",
    ")[\"input_ids\"]\n",
    "\n",
    "output_ids = model.generate(\n",
    "    input_ids=input_ids,\n",
    "    no_repeat_ngram_size=4\n",
    ")[0]\n",
    "\n",
    "summary_6 = tokenizer.decode(output_ids, skip_special_tokens=True)\n",
    "\n",
    "summary_6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8f46b5dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "ARTICLE_5 = \"\"\"\n",
    "Раздел «Хаб» в «Яндекс Go» позволяет планировать поездки на всех видах городского транспорта. Теперь он работает на основе алгоритмов, которые объединяют данные о городе, включая дорожную ситуацию и погоду, рассказали в сервисе.\n",
    "До этого «Хаб» собирал список маршрутов и ранжировал их по стоимости. После обновления он показывает два наиболее подходящих варианта и до пяти дополнительных — если настроить персональные фильтры.\n",
    "Маршруты также сопровождаются короткими подсказками, которые объясняют логику выбора: например, на автобусе можно доехать быстро и без пересадок, или хорошая погода, а идти пешком недалеко.\n",
    "Пользователь может указать привычные виды транспорта — алгоритмы подберут маршруты на основе этих предпочтений. Если нет водительских прав, можно отключить каршеринг — и раздел покажет, как уехать на общественном транспорте или такси.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87665c5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Раздел «Хаб» в «Яндекс Go» позволяет планировать поездки на всех видах городского транспорта. Теперь он работает на основе алгоритмов, которые объединяют данные о городе, включая дорожную ситуацию и погоду.'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = T5ForConditionalGeneration.from_pretrained(model_name)\n",
    "\n",
    "input_ids = tokenizer(\n",
    "    [ARTICLE_5],\n",
    "    max_length=600,\n",
    "    add_special_tokens=True,\n",
    "    padding=\"max_length\",\n",
    "    truncation=True,\n",
    "    return_tensors=\"pt\"\n",
    ")[\"input_ids\"]\n",
    "\n",
    "output_ids = model.generate(\n",
    "    input_ids=input_ids,\n",
    "    no_repeat_ngram_size=4\n",
    ")[0]\n",
    "\n",
    "summary_7 = tokenizer.decode(output_ids, skip_special_tokens=True)\n",
    "\n",
    "summary_7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a222836b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ARTICLE_6 = \"\"\"\n",
    "поисках жизни за пределами Земли ученые прежде всего полагаются на человеческие представления о разуме, языке и технологиях. Отсюда и поиск «техносигнатур» — потенциальных признаков деятельности внеземных цивилизаций, таких как радиосигналы, лазерные импульсы и тепловые аномалии. Ранее, следуя этой логике, участники международного научного проекта Breakthrough Listen безуспешно сканировали тысячи звездных систем на наличие радиосигналов.   \n",
    "Поскольку на Земле существует множество форм коммуникации, в том числе у животных и насекомых, которые развивались независимо от человека, исследователи под руководством Кэмерон Брукс (Cameron Brooks) из Университета штата Аризона (США) обратили внимание на поведение светлячков, которые «разговаривают» вспышками света. По сути, это простейший «язык», созданный эволюцией для привлечения партнеров и распознавания особей своего вида. Свечение их зеленоватых «фонариков» требует минимальных энергетических затрат, но остается отчетливо различимым на фоне природного «шума». То есть выполняет те же задачи, что и потенциальные сигналы инопланетян.\n",
    "\n",
    "Чтобы проверить, могут ли представители внеземных цивилизаций общаться подобно светлячкам, Брукс и коллеги проанализировали данные о тысячах пульсаров из каталога Австралийского национального агентства телескопических наблюдений. Эти космические объекты излучают регулярные импульсы и отлично подходят в качестве «фонового шума» для проверки модели. В результате исследователи создали искусственный сигнал, который, точно вспышка светлячка, требует минимум энергии и отличается от окружающих пульсаров.\n",
    "Расчеты показали, что распознать такой симулированный сигнал можно по его структуре — без расшифровки смысла. То есть, чтобы заметить присутствие внеземного разума, не обязательно понимать его язык: достаточно распознать сигнал, который слишком «организован», чтобы быть случайным. Таким образом, ученые предложили рассматривать коммуникацию как универсальное явление, подчиненное законам эволюции, а не инженерному замыслу. Результаты научной работы опубликованы на сервере препринтов Корнеллского университета. \n",
    "\n",
    "Новая модель симулирует сигналы на фоне пульсаров, подчеркивая их эволюционную «оптимизацию», и помогает уйти от антропоцентризма — привычки судить об инопланетном интеллекте по человеческим меркам. В перспективе подобные алгоритмы можно использовать в системах автоматического поиска аномалий среди астрономических данных, чтобы выделять потенциально искусственные источники — своеобразные «фонарики» в космической тьме, за которыми может скрываться другая цивилизация.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "10225bac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Ученые рассматривают коммуникацию как универсальное явление, подчиненное законам эволюции, а не инженерному замыслу.'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_ids = tokenizer(\n",
    "    [ARTICLE_6],\n",
    "    max_length=600,\n",
    "    add_special_tokens=True,\n",
    "    padding=\"max_length\",\n",
    "    truncation=True,\n",
    "    return_tensors=\"pt\"\n",
    ")[\"input_ids\"]\n",
    "\n",
    "output_ids = model.generate(\n",
    "    input_ids=input_ids,\n",
    "    no_repeat_ngram_size=4\n",
    ")[0]\n",
    "\n",
    "summary_8 = tokenizer.decode(output_ids, skip_special_tokens=True)\n",
    "\n",
    "summary_8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "98eae45e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n",
      "Your input_length: 523 is bigger than 0.9 * max_length: 200. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Китай в понедельник объявил о тарифах до 42,7% на молочные продукты из Европейского союза после результатов антисубсидионного расследования, которое началось в августе 2024 года. В заявлении министерства торговли Китая говорится, что субсидии ЕС на молочные продукты нанесли \"существенный ущерб\" отечественной молочной промышленности Китая. Тарифы начнут действовать 23 декабря, сообщило министерство, и ставки будут определены по количеству \"адваремовых ставок субсидирования\" от Таможенной комиссии страны. Тарифы варьируются от 21,9% до 42,7%, с компаниями, \"которые сотрудничали с расследованием\" в отношении тарифов в размере 28,6%, и теми, кто \"не сотрудничал\" в пределах 42,7%, согласно официальному заявлению Министерства'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translator = pipeline(\n",
    "    \"translation\",\n",
    "    model=\"facebook/nllb-200-distilled-600M\",\n",
    "    src_lang=\"eng_Latn\",   \n",
    "    tgt_lang=\"rus_Cyrl\",   \n",
    "    device=0 if torch.cuda.is_available() else -1\n",
    ")\n",
    "\n",
    "result_1 = translator(ARTICLE_1)\n",
    "result_1[0]['translation_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "22cff4dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`torch_dtype` is deprecated! Use `dtype` instead!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\ashes\\other\\courses_ml\\venv\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCannot execute code, session has been disposed. Please try restarting the Kernel."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCannot execute code, session has been disposed. Please try restarting the Kernel. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "translator = pipeline(\n",
    "    \"text2text-generation\",\n",
    "    model=\"google/madlad400-3b-mt\",\n",
    "    torch_dtype=torch.bfloat16, \n",
    "    device_map=\"auto\"  \n",
    ")\n",
    "\n",
    "result = translator('>>rus<< ' + ARTICLE_1, max_new_tokens=128)\n",
    "print(result[0]['generated_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9c605b35",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "ename": "AcceleratorError",
     "evalue": "CUDA error: device-side assert triggered\nSearch for `cudaErrorAssert' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAcceleratorError\u001b[39m                          Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m translator = \u001b[43mpipeline\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtranslation\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mHelsinki-NLP/opus-mt-en-ru\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      3\u001b[39m result_2 = translator(ARTICLE_3_1)\n\u001b[32m      4\u001b[39m result_2[\u001b[32m0\u001b[39m][\u001b[33m'\u001b[39m\u001b[33mtranslation_text\u001b[39m\u001b[33m'\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\ashes\\other\\courses_ml\\venv\\Lib\\site-packages\\transformers\\pipelines\\__init__.py:1229\u001b[39m, in \u001b[36mpipeline\u001b[39m\u001b[34m(task, model, config, tokenizer, feature_extractor, image_processor, processor, framework, revision, use_fast, token, device, device_map, dtype, trust_remote_code, model_kwargs, pipeline_class, **kwargs)\u001b[39m\n\u001b[32m   1226\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m processor \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   1227\u001b[39m     kwargs[\u001b[33m\"\u001b[39m\u001b[33mprocessor\u001b[39m\u001b[33m\"\u001b[39m] = processor\n\u001b[32m-> \u001b[39m\u001b[32m1229\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpipeline_class\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframework\u001b[49m\u001b[43m=\u001b[49m\u001b[43mframework\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\ashes\\other\\courses_ml\\venv\\Lib\\site-packages\\transformers\\pipelines\\text2text_generation.py:85\u001b[39m, in \u001b[36mText2TextGenerationPipeline.__init__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m     84\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, *args, **kwargs):\n\u001b[32m---> \u001b[39m\u001b[32m85\u001b[39m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     87\u001b[39m     \u001b[38;5;28mself\u001b[39m.check_model_type(\n\u001b[32m     88\u001b[39m         TF_MODEL_FOR_SEQ_TO_SEQ_CAUSAL_LM_MAPPING_NAMES\n\u001b[32m     89\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.framework == \u001b[33m\"\u001b[39m\u001b[33mtf\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     90\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m MODEL_FOR_SEQ_TO_SEQ_CAUSAL_LM_MAPPING_NAMES\n\u001b[32m     91\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\ashes\\other\\courses_ml\\venv\\Lib\\site-packages\\transformers\\pipelines\\base.py:1044\u001b[39m, in \u001b[36mPipeline.__init__\u001b[39m\u001b[34m(self, model, tokenizer, feature_extractor, image_processor, processor, modelcard, framework, task, device, binary_output, **kwargs)\u001b[39m\n\u001b[32m   1037\u001b[39m \u001b[38;5;66;03m# We shouldn't call `model.to()` for models loaded with accelerate as well as the case that model is already on device\u001b[39;00m\n\u001b[32m   1038\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m   1039\u001b[39m     \u001b[38;5;28mself\u001b[39m.framework == \u001b[33m\"\u001b[39m\u001b[33mpt\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1040\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m.model.device != \u001b[38;5;28mself\u001b[39m.device\n\u001b[32m   1041\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m.device, \u001b[38;5;28mint\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m.device < \u001b[32m0\u001b[39m)\n\u001b[32m   1042\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m hf_device_map \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1043\u001b[39m ):\n\u001b[32m-> \u001b[39m\u001b[32m1044\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1046\u001b[39m \u001b[38;5;66;03m# If it's a generation pipeline and the model can generate:\u001b[39;00m\n\u001b[32m   1047\u001b[39m \u001b[38;5;66;03m# 1 - create a local generation config. This is done to avoid side-effects on the model as we apply local\u001b[39;00m\n\u001b[32m   1048\u001b[39m \u001b[38;5;66;03m# tweaks to the generation config.\u001b[39;00m\n\u001b[32m   1049\u001b[39m \u001b[38;5;66;03m# 2 - load the assistant model if it is passed.\u001b[39;00m\n\u001b[32m   1050\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._pipeline_calls_generate \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m.model.can_generate():\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\ashes\\other\\courses_ml\\venv\\Lib\\site-packages\\transformers\\modeling_utils.py:4343\u001b[39m, in \u001b[36mPreTrainedModel.to\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   4338\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m dtype_present_in_args:\n\u001b[32m   4339\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   4340\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mYou cannot cast a GPTQ model in a new `dtype`. Make sure to load the model using `from_pretrained` using the desired\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   4341\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33m `dtype` by passing the correct `dtype` argument.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   4342\u001b[39m         )\n\u001b[32m-> \u001b[39m\u001b[32m4343\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\ashes\\other\\courses_ml\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1371\u001b[39m, in \u001b[36mModule.to\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1368\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1369\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1371\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\ashes\\other\\courses_ml\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:930\u001b[39m, in \u001b[36mModule._apply\u001b[39m\u001b[34m(self, fn, recurse)\u001b[39m\n\u001b[32m    928\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[32m    929\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.children():\n\u001b[32m--> \u001b[39m\u001b[32m930\u001b[39m         \u001b[43mmodule\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    932\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied) -> \u001b[38;5;28mbool\u001b[39m:\n\u001b[32m    933\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m torch._has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[32m    934\u001b[39m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[32m    935\u001b[39m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    940\u001b[39m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[32m    941\u001b[39m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\ashes\\other\\courses_ml\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:930\u001b[39m, in \u001b[36mModule._apply\u001b[39m\u001b[34m(self, fn, recurse)\u001b[39m\n\u001b[32m    928\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[32m    929\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.children():\n\u001b[32m--> \u001b[39m\u001b[32m930\u001b[39m         \u001b[43mmodule\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    932\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied) -> \u001b[38;5;28mbool\u001b[39m:\n\u001b[32m    933\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m torch._has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[32m    934\u001b[39m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[32m    935\u001b[39m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    940\u001b[39m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[32m    941\u001b[39m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\ashes\\other\\courses_ml\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:957\u001b[39m, in \u001b[36mModule._apply\u001b[39m\u001b[34m(self, fn, recurse)\u001b[39m\n\u001b[32m    953\u001b[39m \u001b[38;5;66;03m# Tensors stored in modules are graph leaves, and we don't want to\u001b[39;00m\n\u001b[32m    954\u001b[39m \u001b[38;5;66;03m# track autograd history of `param_applied`, so we have to use\u001b[39;00m\n\u001b[32m    955\u001b[39m \u001b[38;5;66;03m# `with torch.no_grad():`\u001b[39;00m\n\u001b[32m    956\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m torch.no_grad():\n\u001b[32m--> \u001b[39m\u001b[32m957\u001b[39m     param_applied = \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparam\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    958\u001b[39m p_should_use_set_data = compute_should_use_set_data(param, param_applied)\n\u001b[32m    960\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_subclasses\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mfake_tensor\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m FakeTensor\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\ashes\\other\\courses_ml\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1357\u001b[39m, in \u001b[36mModule.to.<locals>.convert\u001b[39m\u001b[34m(t)\u001b[39m\n\u001b[32m   1350\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m convert_to_format \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m t.dim() \u001b[38;5;129;01min\u001b[39;00m (\u001b[32m4\u001b[39m, \u001b[32m5\u001b[39m):\n\u001b[32m   1351\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m t.to(\n\u001b[32m   1352\u001b[39m             device,\n\u001b[32m   1353\u001b[39m             dtype \u001b[38;5;28;01mif\u001b[39;00m t.is_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t.is_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1354\u001b[39m             non_blocking,\n\u001b[32m   1355\u001b[39m             memory_format=convert_to_format,\n\u001b[32m   1356\u001b[39m         )\n\u001b[32m-> \u001b[39m\u001b[32m1357\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mt\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1358\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1359\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m.\u001b[49m\u001b[43mis_floating_point\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m.\u001b[49m\u001b[43mis_complex\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   1360\u001b[39m \u001b[43m        \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1361\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1362\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m   1363\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(e) == \u001b[33m\"\u001b[39m\u001b[33mCannot copy out of meta tensor; no data!\u001b[39m\u001b[33m\"\u001b[39m:\n",
      "\u001b[31mAcceleratorError\u001b[39m: CUDA error: device-side assert triggered\nSearch for `cudaErrorAssert' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
     ]
    }
   ],
   "source": [
    "translator = pipeline(\"translation\", model=\"Helsinki-NLP/opus-mt-en-ru\")\n",
    "\n",
    "result_2 = translator(ARTICLE_3_1)\n",
    "result_2[0]['translation_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c29eb1e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "translator_2 = pipeline(\"text2text-generation\", model=\"google-t5/t5-small\")\n",
    "\n",
    "result_3 = translator('translate English to Russian: ' + ARTICLE_3)\n",
    "result_3[0]['translation_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8fa6540",
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=\"ModelSpace/GemmaX2-28-2B-v0.1\",\n",
    "    dtype=torch.bfloat16,\n",
    "    device_map=\"auto\"\n",
    ")\n",
    "\n",
    "prompt = f\"\"\"Translate the following Russian text to English:\n",
    "\n",
    "Russian: {ARTICLE_4}\n",
    "English:\"\"\"\n",
    "\n",
    "result = generator(\n",
    "    prompt, \n",
    "    max_new_tokens=100,\n",
    "    temperature=0.1, \n",
    "    do_sample=False \n",
    ")\n",
    "print(result[0]['generated_text'].split(\"English:\")[-1].strip())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
