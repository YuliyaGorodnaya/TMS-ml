{"cells":[{"cell_type":"code","execution_count":null,"id":"79610594","metadata":{"id":"79610594"},"outputs":[],"source":["import warnings\n","warnings.filterwarnings('ignore')"]},{"cell_type":"code","execution_count":null,"id":"f5a842ee","metadata":{"id":"f5a842ee"},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","\n","import nltk, re\n","from nltk.corpus import stopwords\n","from nltk.stem import WordNetLemmatizer\n","from collections import Counter\n","from scipy.sparse import hstack\n","\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n","from sklearn.svm import LinearSVC\n","from sklearn.ensemble import RandomForestClassifier\n"]},{"cell_type":"code","execution_count":null,"id":"adc1d392","metadata":{"id":"adc1d392"},"outputs":[],"source":["df = pd.read_csv('src/fake_news_dataset.csv')"]},{"cell_type":"code","execution_count":null,"id":"d9bc7577","metadata":{"id":"d9bc7577"},"outputs":[],"source":["tfidf = TfidfVectorizer(\n","    max_features=50000,\n","    ngram_range=(1, 2),\n","    min_df=5,\n","    max_df=0.9\n",")\n","X_tfidf = tfidf.fit_transform(df['text'])\n","y = df['label'].map({'fake': 1, 'real': 0}).values"]},{"cell_type":"code","execution_count":null,"id":"df31ca1a","metadata":{"id":"df31ca1a"},"outputs":[],"source":["X_train, X_test, y_train, y_test = train_test_split(\n","    X_tfidf, y, test_size=0.2, random_state=42, stratify=y\n",")"]},{"cell_type":"code","execution_count":null,"id":"ce6e3467","metadata":{"id":"ce6e3467"},"outputs":[],"source":["clf_lr = LogisticRegression(\n","    max_iter=200,\n","    C=2.0,\n","    n_jobs=-1\n",")\n","clf_lr.fit(X_train, y_train)\n","pred = clf_lr.predict(X_test)"]},{"cell_type":"code","execution_count":null,"id":"bbc8eb5d","metadata":{"id":"bbc8eb5d","outputId":"635c53a3-1adf-41f3-d504-9bab56ed4489"},"outputs":[{"name":"stdout","output_type":"stream","text":["acc = 0.5035\n","f1 = 0.5165530671859786\n","precision_score = 0.5059608965188365\n","recall_score = 0.5275982098458478\n"]}],"source":["acc = accuracy_score(y_test, pred)\n","f1 = f1_score(y_test, pred)\n","prec = precision_score(y_test, pred)\n","recall = recall_score(y_test, pred)\n","\n","print(f'acc = {acc}\\nf1 = {f1}\\nprecision_score = {prec}\\nrecall_score = {recall}')"]},{"cell_type":"code","execution_count":null,"id":"c2a0b8d2","metadata":{"id":"c2a0b8d2"},"outputs":[],"source":["clf_svm = LinearSVC()\n","clf_svm.fit(X_train, y_train)\n","pred = clf_svm.predict(X_test)"]},{"cell_type":"code","execution_count":null,"id":"3e323c51","metadata":{"id":"3e323c51","outputId":"7ceccd87-bd50-4a0a-c0b9-37b5b408780e"},"outputs":[{"name":"stdout","output_type":"stream","text":["acc = 0.5045\n","f1 = 0.5146914789422136\n","precision_score = 0.5069946936806561\n","recall_score = 0.5226255594231726\n"]}],"source":["acc = accuracy_score(y_test, pred)\n","f1 = f1_score(y_test, pred)\n","prec = precision_score(y_test, pred)\n","recall = recall_score(y_test, pred)\n","\n","print(f'acc = {acc}\\nf1 = {f1}\\nprecision_score = {prec}\\nrecall_score = {recall}')"]},{"cell_type":"code","execution_count":null,"id":"3f37eb75","metadata":{"id":"3f37eb75"},"outputs":[],"source":["rf = RandomForestClassifier(\n","    n_estimators=300,\n","    class_weight='balanced'\n",")\n","rf.fit(X_train, y_train)\n","pred = rf.predict(X_test)"]},{"cell_type":"code","execution_count":null,"id":"28df1451","metadata":{"id":"28df1451","outputId":"8846ac58-2586-40b3-f52d-c5cc771b41ee"},"outputs":[{"name":"stdout","output_type":"stream","text":["acc = 0.512\n","f1 = 0.5601622352410996\n","precision_score = 0.5121549237742068\n","recall_score = 0.618100447538538\n"]}],"source":["acc = accuracy_score(y_test, pred)\n","f1 = f1_score(y_test, pred)\n","prec = precision_score(y_test, pred)\n","recall = recall_score(y_test, pred)\n","\n","print(f'acc = {acc}\\nf1 = {f1}\\nprecision_score = {prec}\\nrecall_score = {recall}')"]},{"cell_type":"code","execution_count":null,"id":"a5bbfe25","metadata":{"id":"a5bbfe25"},"outputs":[],"source":["stop_words = set(stopwords.words('english'))\n","stop_words.update(['mr', 'else'])\n","lemmatizer = WordNetLemmatizer()\n","\n","def preprocess(text, reg=r'[^a-zA-Z\\s]'):\n","    text = re.sub(reg, '', text.lower())\n","    tokens = nltk.word_tokenize(text)\n","    return [lemmatizer.lemmatize(w) for w in tokens if w not in stop_words]"]},{"cell_type":"code","execution_count":null,"id":"42a90318","metadata":{"id":"42a90318"},"outputs":[],"source":["df['tokens'] = df['text'].apply(preprocess)"]},{"cell_type":"code","execution_count":null,"id":"1060436d","metadata":{"id":"1060436d"},"outputs":[],"source":["labels = df['label'].tolist()\n","\n","feature_names = np.array(tfidf.get_feature_names_out())\n","\n","def top_tfidf_words(label_value, top_n=20):\n","    idx = np.where(np.array(labels) == label_value)[0]\n","    class_tfidf = X_tfidf[idx].mean(axis=0).A1\n","    top_idx = np.argsort(class_tfidf)[::-1][:top_n]\n","    return pd.DataFrame({\n","        'term': feature_names[top_idx],\n","        'mean_tfidf': class_tfidf[top_idx]\n","    })\n","\n","top_fake = top_tfidf_words('fake')\n","top_real = top_tfidf_words('real')"]},{"cell_type":"code","execution_count":null,"id":"00cf2f25","metadata":{"id":"00cf2f25"},"outputs":[],"source":["fake_terms = top_fake['term'].tolist()\n","real_terms = top_real['term'].tolist()\n","\n","fake_set = set(fake_terms)\n","real_set = set(real_terms)\n","\n","def has_fake_tfidf(tokens):\n","    return int(any(t in fake_set for t in tokens))\n","\n","def has_real_tfidf(tokens):\n","    return int(any(t in real_set for t in tokens))\n","\n","df['has_fake_tfidf'] = df['tokens'].apply(has_fake_tfidf)\n","df['has_real_tfidf'] = df['tokens'].apply(has_real_tfidf)"]},{"cell_type":"code","execution_count":null,"id":"f97267f3","metadata":{"id":"f97267f3"},"outputs":[],"source":["def tfidf_counts(tokens):\n","    c = Counter(tokens)\n","    fake_count = sum(c[w] for w in fake_set)\n","    real_count = sum(c[w] for w in real_set)\n","    return pd.Series({'fake_tfidf_count': fake_count,\n","                      'real_tfidf_count': real_count})\n","\n","df[['fake_tfidf_count', 'real_tfidf_count']] = df['tokens'].apply(tfidf_counts)\n","\n","df['len_tokens'] = df['tokens'].apply(len)\n","df['fake_tfidf_frac'] = df['fake_tfidf_count'] / df['len_tokens'].clip(lower=1)\n","df['real_tfidf_frac'] = df['real_tfidf_count'] / df['len_tokens'].clip(lower=1)"]},{"cell_type":"code","execution_count":null,"id":"0fae4328","metadata":{"id":"0fae4328"},"outputs":[],"source":["e_cols = ['has_fake_tfidf', 'has_real_tfidf',\n","              'fake_tfidf_frac', 'real_tfidf_frac', 'len_tokens']\n","e_X = df[e_cols].to_numpy().astype(float)"]},{"cell_type":"code","execution_count":null,"id":"fc5af74f","metadata":{"id":"fc5af74f"},"outputs":[],"source":["X = hstack([X_tfidf, e_X])"]},{"cell_type":"code","execution_count":null,"id":"0a638788","metadata":{"id":"0a638788"},"outputs":[],"source":["X_train, X_test, y_train, y_test = train_test_split(\n","    X, y, test_size=0.2, random_state=42, stratify=y\n",")"]},{"cell_type":"code","execution_count":null,"id":"d9ce75de","metadata":{"id":"d9ce75de"},"outputs":[],"source":["clf = LogisticRegression(\n","    max_iter=200,\n","    C=2.0,\n","    n_jobs=-1\n",")\n","clf.fit(X_train, y_train)\n","pred = clf.predict(X_test)"]},{"cell_type":"code","execution_count":null,"id":"d8f77b71","metadata":{"id":"d8f77b71","outputId":"3dcc5c14-79c7-4bcd-c2e5-b55d14cb1823"},"outputs":[{"name":"stdout","output_type":"stream","text":["acc = 0.507\n","f1 = 0.5201946472019465\n","precision_score = 0.5092901381610291\n","recall_score = 0.5315763301839881\n"]}],"source":["acc = accuracy_score(y_test, pred)\n","f1 = f1_score(y_test, pred)\n","prec = precision_score(y_test, pred)\n","recall = recall_score(y_test, pred)\n","\n","print(f'acc = {acc}\\nf1 = {f1}\\nprecision_score = {prec}\\nrecall_score = {recall}')"]},{"cell_type":"code","execution_count":null,"id":"68e1ec04","metadata":{"id":"68e1ec04","outputId":"d224a6c1-bb3b-447b-9c09-a60393fecf92"},"outputs":[{"name":"stdout","output_type":"stream","text":["WARNING:tensorflow:From c:\\ashes\\other\\courses_ml\\venv\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n","\n"]}],"source":["from datasets import Dataset\n","from transformers import (\n","    AutoTokenizer,\n","    AutoModelForSequenceClassification,\n","    TrainingArguments,\n","    Trainer,\n","    BertTokenizer,\n","    BertForSequenceClassification\n",")\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import classification_report\n","import torch"]},{"cell_type":"code","execution_count":null,"id":"d1b5ec75","metadata":{"id":"d1b5ec75"},"outputs":[],"source":["df['label_id'] = df['label'].map({'real': 0, 'fake': 1}).astype(int)\n","\n","train_df, test_df = train_test_split(\n","    df, test_size=0.2, random_state=42, stratify=df['label_id']\n",")\n","\n","train_ds = Dataset.from_pandas(train_df[['text', 'label_id']])\n","test_ds  = Dataset.from_pandas(test_df[['text', 'label_id']])\n"]},{"cell_type":"code","execution_count":null,"id":"8164a366","metadata":{"id":"8164a366","outputId":"928e1e74-4fe7-4822-d039-f0c77c1a8377"},"outputs":[{"name":"stderr","output_type":"stream","text":["Map: 100%|██████████| 16000/16000 [00:02<00:00, 6881.18 examples/s]\n","Map: 100%|██████████| 4000/4000 [00:00<00:00, 7818.87 examples/s]\n"]}],"source":["MODEL_NAME = 'distilbert-base-uncased'\n","\n","tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n","\n","MAX_LEN = 128\n","\n","def tokenize_batch(batch):\n","    return tokenizer(\n","        batch['text'],\n","        padding='max_length',\n","        truncation=True,\n","        max_length=MAX_LEN\n","    )\n","\n","train_ds_tok = train_ds.map(tokenize_batch, batched=True)\n","test_ds_tok  = test_ds.map(tokenize_batch, batched=True)\n","\n","train_ds_tok = train_ds_tok.rename_column('label_id', 'label')\n","test_ds_tok  = test_ds_tok.rename_column('label_id', 'label')\n","\n","train_ds_tok.set_format(\n","    type='torch',\n","    columns=['input_ids', 'attention_mask', 'label']\n",")\n","test_ds_tok.set_format(\n","    type='torch',\n","    columns=['input_ids', 'attention_mask', 'label']\n",")\n"]},{"cell_type":"code","execution_count":null,"id":"7860e343","metadata":{"id":"7860e343","outputId":"6c339224-efbd-402b-e60a-6b658df2103f"},"outputs":[{"name":"stderr","output_type":"stream","text":["Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]}],"source":["model = AutoModelForSequenceClassification.from_pretrained(\n","    MODEL_NAME,\n","    num_labels=2\n",")\n","\n","device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","model.to(device)\n","\n","batch_size = 8\n","\n","training_args = TrainingArguments(\n","    output_dir='lesson31',\n","    eval_strategy='epoch',\n","    save_strategy='epoch',\n","    learning_rate=0.001,\n","    per_device_train_batch_size=batch_size,\n","    per_device_eval_batch_size=batch_size,\n","    num_train_epochs=3,\n","    weight_decay=0.01,\n","    logging_steps=100,\n","    report_to=\"none\"\n",")\n"]},{"cell_type":"code","execution_count":null,"id":"fae6120a","metadata":{"id":"fae6120a"},"outputs":[],"source":["def compute_metrics(eval_pred):\n","    logits, labels = eval_pred\n","    preds = np.argmax(logits, axis=-1)\n","    report = classification_report(labels, preds, output_dict=True, zero_division=0)\n","    return {\n","        \"precision_fake\": report[\"1\"][\"precision\"],\n","        \"recall_fake\": report[\"1\"][\"recall\"],\n","        \"f1_fake\": report[\"1\"][\"f1-score\"],\n","        \"accuracy\": report[\"accuracy\"],\n","    }\n","\n","trainer = Trainer(\n","    model=model,\n","    args=training_args,\n","    train_dataset=train_ds_tok,\n","    eval_dataset=test_ds_tok,\n","    tokenizer=tokenizer,\n","    compute_metrics=compute_metrics,\n",")\n"]},{"cell_type":"code","execution_count":null,"id":"cb35afbd","metadata":{"id":"cb35afbd","outputId":"6af53370-2e03-4470-d784-bbcdd4566e70"},"outputs":[{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='6000' max='6000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [6000/6000 09:09, Epoch 3/3]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Precision Fake</th>\n","      <th>Recall Fake</th>\n","      <th>F1 Fake</th>\n","      <th>Accuracy</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>0.694600</td>\n","      <td>0.693135</td>\n","      <td>0.502750</td>\n","      <td>1.000000</td>\n","      <td>0.669107</td>\n","      <td>0.502750</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.693200</td>\n","      <td>0.693345</td>\n","      <td>0.502750</td>\n","      <td>1.000000</td>\n","      <td>0.669107</td>\n","      <td>0.502750</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>0.693200</td>\n","      <td>0.693133</td>\n","      <td>0.502750</td>\n","      <td>1.000000</td>\n","      <td>0.669107</td>\n","      <td>0.502750</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["'              precision    recall  f1-score   support\\n\\n        real       0.00      0.00      0.00      1989\\n        fake       0.50      1.00      0.67      2011\\n\\n    accuracy                           0.50      4000\\n   macro avg       0.25      0.50      0.33      4000\\nweighted avg       0.25      0.50      0.34      4000\\n'"]},"execution_count":9,"metadata":{},"output_type":"execute_result"}],"source":["trainer.train()\n","\n","pred_out = trainer.predict(test_ds_tok)\n","logits = pred_out.predictions\n","y_true = pred_out.label_ids\n","y_pred = np.argmax(logits, axis=-1)\n","\n","classification_report(y_true, y_pred, target_names=['real', 'fake'])"]},{"cell_type":"markdown","source":["С БЕРТ тоже печаль..."],"metadata":{"id":"9IamnZ3GvmM8"},"id":"9IamnZ3GvmM8"}],"metadata":{"kernelspec":{"display_name":"venv","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.13.9"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":5}