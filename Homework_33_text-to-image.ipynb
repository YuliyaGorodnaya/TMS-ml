{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f177382c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1b68ff20",
   "metadata": {},
   "outputs": [],
   "source": [
    "from diffusers import DiffusionPipeline, LCMScheduler\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "861f66e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading pipeline components...: 100%|██████████| 7/7 [00:27<00:00,  3.91s/it]\n",
      "The config attributes {'skip_prk_steps': True} were passed to LCMScheduler, but are not expected and will be ignored. Please verify your scheduler_config.json configuration file.\n",
      "No LoRA keys associated to CLIPTextModel found with the prefix='text_encoder'. This is safe to ignore if LoRA state dict didn't originally have any CLIPTextModel related params. You can also try specifying `prefix=None` to resolve the warning. Otherwise, open an issue if you think it's unexpected: https://github.com/huggingface/diffusers/issues/new\n",
      "No LoRA keys associated to CLIPTextModelWithProjection found with the prefix='text_encoder_2'. This is safe to ignore if LoRA state dict didn't originally have any CLIPTextModelWithProjection related params. You can also try specifying `prefix=None` to resolve the warning. Otherwise, open an issue if you think it's unexpected: https://github.com/huggingface/diffusers/issues/new\n",
      "No LoRA keys associated to CLIPTextModel found with the prefix='text_encoder'. This is safe to ignore if LoRA state dict didn't originally have any CLIPTextModel related params. You can also try specifying `prefix=None` to resolve the warning. Otherwise, open an issue if you think it's unexpected: https://github.com/huggingface/diffusers/issues/new\n",
      "No LoRA keys associated to CLIPTextModelWithProjection found with the prefix='text_encoder_2'. This is safe to ignore if LoRA state dict didn't originally have any CLIPTextModelWithProjection related params. You can also try specifying `prefix=None` to resolve the warning. Otherwise, open an issue if you think it's unexpected: https://github.com/huggingface/diffusers/issues/new\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "StableDiffusionXLPipeline {\n",
       "  \"_class_name\": \"StableDiffusionXLPipeline\",\n",
       "  \"_diffusers_version\": \"0.37.0.dev0\",\n",
       "  \"_name_or_path\": \"stabilityai/stable-diffusion-xl-base-1.0\",\n",
       "  \"feature_extractor\": [\n",
       "    null,\n",
       "    null\n",
       "  ],\n",
       "  \"force_zeros_for_empty_prompt\": true,\n",
       "  \"image_encoder\": [\n",
       "    null,\n",
       "    null\n",
       "  ],\n",
       "  \"scheduler\": [\n",
       "    \"diffusers\",\n",
       "    \"LCMScheduler\"\n",
       "  ],\n",
       "  \"text_encoder\": [\n",
       "    \"transformers\",\n",
       "    \"CLIPTextModel\"\n",
       "  ],\n",
       "  \"text_encoder_2\": [\n",
       "    \"transformers\",\n",
       "    \"CLIPTextModelWithProjection\"\n",
       "  ],\n",
       "  \"tokenizer\": [\n",
       "    \"transformers\",\n",
       "    \"CLIPTokenizer\"\n",
       "  ],\n",
       "  \"tokenizer_2\": [\n",
       "    \"transformers\",\n",
       "    \"CLIPTokenizer\"\n",
       "  ],\n",
       "  \"unet\": [\n",
       "    \"diffusers\",\n",
       "    \"UNet2DConditionModel\"\n",
       "  ],\n",
       "  \"vae\": [\n",
       "    \"diffusers\",\n",
       "    \"AutoencoderKL\"\n",
       "  ]\n",
       "}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_id = \"stabilityai/stable-diffusion-xl-base-1.0\"\n",
    "lcm_lora_id = \"latent-consistency/lcm-lora-sdxl\"\n",
    "pipe = DiffusionPipeline.from_pretrained(model_id, variant=\"fp16\")\n",
    "pipe.scheduler = LCMScheduler.from_config(pipe.scheduler.config)\n",
    "\n",
    "pipe.load_lora_weights(lcm_lora_id, adapter_name=\"lora\")\n",
    "pipe.load_lora_weights(\"nerijs/pixel-art-xl\", weight_name=\"pixel-art-xl.safetensors\", adapter_name=\"pixel\")\n",
    "\n",
    "pipe.set_adapters([\"lora\", \"pixel\"], adapter_weights=[1.0, 1.2])\n",
    "pipe.to(device=\"cuda\", dtype=torch.float16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0959cf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = 'Anime style masterpiece, winter night atmosphere. A cute anime Snegurochka-chan (Snow Maiden) with long blue braids and a sparkling kokoshnik is sitting at a festive feast table next to a friendly anthropomorphic shark wearing a Santa hat. The table is overflowing with mountains of bright orange tangerines, champagne glasses, and festive food. In the background, the illuminated Rumyantsev-Paskevich Palace in Gomel stands majestically in a snowy park. Fireworks in the dark sky, falling snow, cozy warm lighting, detailed texture, 8k resolution, cinematic composition.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4a65da00",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [02:32<00:00, 19.01s/it]\n"
     ]
    }
   ],
   "source": [
    "pipe.enable_model_cpu_offload()\n",
    "prompt = \"snow maiden\"\n",
    "negative_prompt = \"3d render, realistic\"\n",
    "\n",
    "img = pipe(\n",
    "    prompt=prompt,\n",
    "    negative_prompt=negative_prompt,\n",
    "    num_inference_steps=8,\n",
    "    guidance_scale=1.5,\n",
    ").images[0]\n",
    "\n",
    "img.save(f\"snow_maiden.png\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
