{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPKXdEDRlYVeSuCmCq9jU48"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":477},"id":"P0fEXyFJFw-H","executionInfo":{"status":"ok","timestamp":1763992322982,"user_tz":-180,"elapsed":501,"user":{"displayName":"Юлия Гор.","userId":"08838257762277085118"}},"outputId":"69707403-d25f-4dde-bcea-833818fb16ad"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["               Алгоритм / Библиотека                        Скорость  \\\n","0          YOLO11n-Seg (Ultralytics)  Очень высокая (реальное время)   \n","1    MMSegmentation (PSPNet, ADE20K)                         Средняя   \n","2  Segmentation Models PyTorch (SMP)                 Средняя–высокая   \n","3                         Detectron2                         Средняя   \n","4                    Torchvision FCN                         Средняя   \n","5             Torchvision DeepLab v3                         Средняя   \n","6             Torchvision Mask R-CNN                  Низкая–средняя   \n","7         OpenCV (GrabCut/Watershed)     Высокая (но простые методы)   \n","\n","                      Датасет обучения               Кол-во классов  \\\n","0                                 COCO                           80   \n","1                               ADE20K                          150   \n","2  Разные (ImageNet, COCO, Cityscapes)  Зависит от модели (до 150+)   \n","3                                 COCO                          80+   \n","4                                 COCO          21 (VOC), 80 (COCO)   \n","5                                 COCO          21 (VOC), 80 (COCO)   \n","6                                 COCO                          80+   \n","7     Нет (алгоритмы без предобучения)             Ограничено (2–5)   \n","\n","                                  Лучшие сценарии  \\\n","0                 Видео, камеры, потоковые данные   \n","1                       Городские сцены, интерьер   \n","2  Гибкая настройка под медицину, дороги, объекты   \n","3            Instance segmentation, сложные сцены   \n","4               Базовая семантическая сегментация   \n","5                         Городские сцены, дороги   \n","6        Instance segmentation (объекты в сценах)   \n","7                 Простая сегментация, фон/объект   \n","\n","                Точность (mIoU/mAP) Макс. объектов на картинке  \\\n","0                       mAP ~50–53%                      Сотни   \n","1                mIoU ~43% (ADE20K)              Десятки–сотни   \n","2       До 0.9 IoU (на мед. данных)                    Десятки   \n","3                       mAP ~37–40%                      Сотни   \n","4                   mIoU ~62% (VOC)                    Десятки   \n","5            mIoU ~82% (Cityscapes)                    Десятки   \n","6                       mAP ~37–40%                      Сотни   \n","7  Зависит от задачи, обычно низкая                 Ограничено   \n","\n","                                   Личные наблюдения  \n","0  Быстро, просто, но не так точно, как хотелось ...  \n","1        - (проблема с зависимостями в GoogleCollab)  \n","2  Нет предобученных весов, нужно подбирать датас...  \n","3  Медленнее YOLO, но очень хорошо сегментирует, ...  \n","4  Небыстро, но с задачей справляется, хоть и с н...  \n","5  Небыстро, путает мелкие предметы, отлично спра...  \n","6                Небыстро, но с задачей справляется.  \n","7  Плохо справляется, делит на объект/фон. Нет пр...  "],"text/html":["\n","  <div id=\"df-96294344-0ad9-4b33-964f-1a4fc35a0c0e\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Алгоритм / Библиотека</th>\n","      <th>Скорость</th>\n","      <th>Датасет обучения</th>\n","      <th>Кол-во классов</th>\n","      <th>Лучшие сценарии</th>\n","      <th>Точность (mIoU/mAP)</th>\n","      <th>Макс. объектов на картинке</th>\n","      <th>Личные наблюдения</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>YOLO11n-Seg (Ultralytics)</td>\n","      <td>Очень высокая (реальное время)</td>\n","      <td>COCO</td>\n","      <td>80</td>\n","      <td>Видео, камеры, потоковые данные</td>\n","      <td>mAP ~50–53%</td>\n","      <td>Сотни</td>\n","      <td>Быстро, просто, но не так точно, как хотелось ...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>MMSegmentation (PSPNet, ADE20K)</td>\n","      <td>Средняя</td>\n","      <td>ADE20K</td>\n","      <td>150</td>\n","      <td>Городские сцены, интерьер</td>\n","      <td>mIoU ~43% (ADE20K)</td>\n","      <td>Десятки–сотни</td>\n","      <td>- (проблема с зависимостями в GoogleCollab)</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Segmentation Models PyTorch (SMP)</td>\n","      <td>Средняя–высокая</td>\n","      <td>Разные (ImageNet, COCO, Cityscapes)</td>\n","      <td>Зависит от модели (до 150+)</td>\n","      <td>Гибкая настройка под медицину, дороги, объекты</td>\n","      <td>До 0.9 IoU (на мед. данных)</td>\n","      <td>Десятки</td>\n","      <td>Нет предобученных весов, нужно подбирать датас...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Detectron2</td>\n","      <td>Средняя</td>\n","      <td>COCO</td>\n","      <td>80+</td>\n","      <td>Instance segmentation, сложные сцены</td>\n","      <td>mAP ~37–40%</td>\n","      <td>Сотни</td>\n","      <td>Медленнее YOLO, но очень хорошо сегментирует, ...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Torchvision FCN</td>\n","      <td>Средняя</td>\n","      <td>COCO</td>\n","      <td>21 (VOC), 80 (COCO)</td>\n","      <td>Базовая семантическая сегментация</td>\n","      <td>mIoU ~62% (VOC)</td>\n","      <td>Десятки</td>\n","      <td>Небыстро, но с задачей справляется, хоть и с н...</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>Torchvision DeepLab v3</td>\n","      <td>Средняя</td>\n","      <td>COCO</td>\n","      <td>21 (VOC), 80 (COCO)</td>\n","      <td>Городские сцены, дороги</td>\n","      <td>mIoU ~82% (Cityscapes)</td>\n","      <td>Десятки</td>\n","      <td>Небыстро, путает мелкие предметы, отлично спра...</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>Torchvision Mask R-CNN</td>\n","      <td>Низкая–средняя</td>\n","      <td>COCO</td>\n","      <td>80+</td>\n","      <td>Instance segmentation (объекты в сценах)</td>\n","      <td>mAP ~37–40%</td>\n","      <td>Сотни</td>\n","      <td>Небыстро, но с задачей справляется.</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>OpenCV (GrabCut/Watershed)</td>\n","      <td>Высокая (но простые методы)</td>\n","      <td>Нет (алгоритмы без предобучения)</td>\n","      <td>Ограничено (2–5)</td>\n","      <td>Простая сегментация, фон/объект</td>\n","      <td>Зависит от задачи, обычно низкая</td>\n","      <td>Ограничено</td>\n","      <td>Плохо справляется, делит на объект/фон. Нет пр...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-96294344-0ad9-4b33-964f-1a4fc35a0c0e')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-96294344-0ad9-4b33-964f-1a4fc35a0c0e button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-96294344-0ad9-4b33-964f-1a4fc35a0c0e');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","    <div id=\"df-b57421b9-5b47-4b54-9b5a-c75d1666a2c6\">\n","      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-b57421b9-5b47-4b54-9b5a-c75d1666a2c6')\"\n","                title=\"Suggest charts\"\n","                style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","      </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","      <script>\n","        async function quickchart(key) {\n","          const quickchartButtonEl =\n","            document.querySelector('#' + key + ' button');\n","          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","          quickchartButtonEl.classList.add('colab-df-spinner');\n","          try {\n","            const charts = await google.colab.kernel.invokeFunction(\n","                'suggestCharts', [key], {});\n","          } catch (error) {\n","            console.error('Error during call to suggestCharts:', error);\n","          }\n","          quickchartButtonEl.classList.remove('colab-df-spinner');\n","          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","        }\n","        (() => {\n","          let quickchartButtonEl =\n","            document.querySelector('#df-b57421b9-5b47-4b54-9b5a-c75d1666a2c6 button');\n","          quickchartButtonEl.style.display =\n","            google.colab.kernel.accessAllowed ? 'block' : 'none';\n","        })();\n","      </script>\n","    </div>\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","variable_name":"df","summary":"{\n  \"name\": \"df\",\n  \"rows\": 8,\n  \"fields\": [\n    {\n      \"column\": \"\\u0410\\u043b\\u0433\\u043e\\u0440\\u0438\\u0442\\u043c / \\u0411\\u0438\\u0431\\u043b\\u0438\\u043e\\u0442\\u0435\\u043a\\u0430\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 8,\n        \"samples\": [\n          \"MMSegmentation (PSPNet, ADE20K)\",\n          \"Torchvision DeepLab v3\",\n          \"YOLO11n-Seg (Ultralytics)\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"\\u0421\\u043a\\u043e\\u0440\\u043e\\u0441\\u0442\\u044c\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"\\u0421\\u0440\\u0435\\u0434\\u043d\\u044f\\u044f\",\n          \"\\u0412\\u044b\\u0441\\u043e\\u043a\\u0430\\u044f (\\u043d\\u043e \\u043f\\u0440\\u043e\\u0441\\u0442\\u044b\\u0435 \\u043c\\u0435\\u0442\\u043e\\u0434\\u044b)\",\n          \"\\u0421\\u0440\\u0435\\u0434\\u043d\\u044f\\u044f\\u2013\\u0432\\u044b\\u0441\\u043e\\u043a\\u0430\\u044f\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"\\u0414\\u0430\\u0442\\u0430\\u0441\\u0435\\u0442 \\u043e\\u0431\\u0443\\u0447\\u0435\\u043d\\u0438\\u044f\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"ADE20K\",\n          \"\\u041d\\u0435\\u0442 (\\u0430\\u043b\\u0433\\u043e\\u0440\\u0438\\u0442\\u043c\\u044b \\u0431\\u0435\\u0437 \\u043f\\u0440\\u0435\\u0434\\u043e\\u0431\\u0443\\u0447\\u0435\\u043d\\u0438\\u044f)\",\n          \"COCO\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"\\u041a\\u043e\\u043b-\\u0432\\u043e \\u043a\\u043b\\u0430\\u0441\\u0441\\u043e\\u0432\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 6,\n        \"samples\": [\n          \"80\",\n          \"150\",\n          \"\\u041e\\u0433\\u0440\\u0430\\u043d\\u0438\\u0447\\u0435\\u043d\\u043e (2\\u20135)\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"\\u041b\\u0443\\u0447\\u0448\\u0438\\u0435 \\u0441\\u0446\\u0435\\u043d\\u0430\\u0440\\u0438\\u0438\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 8,\n        \"samples\": [\n          \"\\u0413\\u043e\\u0440\\u043e\\u0434\\u0441\\u043a\\u0438\\u0435 \\u0441\\u0446\\u0435\\u043d\\u044b, \\u0438\\u043d\\u0442\\u0435\\u0440\\u044c\\u0435\\u0440\",\n          \"\\u0413\\u043e\\u0440\\u043e\\u0434\\u0441\\u043a\\u0438\\u0435 \\u0441\\u0446\\u0435\\u043d\\u044b, \\u0434\\u043e\\u0440\\u043e\\u0433\\u0438\",\n          \"\\u0412\\u0438\\u0434\\u0435\\u043e, \\u043a\\u0430\\u043c\\u0435\\u0440\\u044b, \\u043f\\u043e\\u0442\\u043e\\u043a\\u043e\\u0432\\u044b\\u0435 \\u0434\\u0430\\u043d\\u043d\\u044b\\u0435\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"\\u0422\\u043e\\u0447\\u043d\\u043e\\u0441\\u0442\\u044c (mIoU/mAP)\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 7,\n        \"samples\": [\n          \"mAP ~50\\u201353%\",\n          \"mIoU ~43% (ADE20K)\",\n          \"mIoU ~82% (Cityscapes)\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"\\u041c\\u0430\\u043a\\u0441. \\u043e\\u0431\\u044a\\u0435\\u043a\\u0442\\u043e\\u0432 \\u043d\\u0430 \\u043a\\u0430\\u0440\\u0442\\u0438\\u043d\\u043a\\u0435\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"\\u0414\\u0435\\u0441\\u044f\\u0442\\u043a\\u0438\\u2013\\u0441\\u043e\\u0442\\u043d\\u0438\",\n          \"\\u041e\\u0433\\u0440\\u0430\\u043d\\u0438\\u0447\\u0435\\u043d\\u043e\",\n          \"\\u0421\\u043e\\u0442\\u043d\\u0438\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"\\u041b\\u0438\\u0447\\u043d\\u044b\\u0435 \\u043d\\u0430\\u0431\\u043b\\u044e\\u0434\\u0435\\u043d\\u0438\\u044f\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 8,\n        \"samples\": [\n          \"- (\\u043f\\u0440\\u043e\\u0431\\u043b\\u0435\\u043c\\u0430 \\u0441 \\u0437\\u0430\\u0432\\u0438\\u0441\\u0438\\u043c\\u043e\\u0441\\u0442\\u044f\\u043c\\u0438 \\u0432 GoogleCollab)\",\n          \"\\u041d\\u0435\\u0431\\u044b\\u0441\\u0442\\u0440\\u043e, \\u043f\\u0443\\u0442\\u0430\\u0435\\u0442 \\u043c\\u0435\\u043b\\u043a\\u0438\\u0435 \\u043f\\u0440\\u0435\\u0434\\u043c\\u0435\\u0442\\u044b, \\u043e\\u0442\\u043b\\u0438\\u0447\\u043d\\u043e \\u0441\\u043f\\u0440\\u0430\\u0432\\u043b\\u044f\\u0435\\u0442\\u0441\\u044f \\u0441 \\u0433\\u043e\\u0440\\u043e\\u0434\\u0441\\u043a\\u0438\\u043c\\u0438 \\u043f\\u0435\\u0439\\u0437\\u0430\\u0436\\u0430\\u043c\\u0438, \\u043f\\u0440\\u043e\\u0435\\u0437\\u0436\\u0435\\u0439 \\u0447\\u0430\\u0441\\u0442\\u044c\\u044e\",\n          \"\\u0411\\u044b\\u0441\\u0442\\u0440\\u043e, \\u043f\\u0440\\u043e\\u0441\\u0442\\u043e, \\u043d\\u043e \\u043d\\u0435 \\u0442\\u0430\\u043a \\u0442\\u043e\\u0447\\u043d\\u043e, \\u043a\\u0430\\u043a \\u0445\\u043e\\u0442\\u0435\\u043b\\u043e\\u0441\\u044c \\u0431\\u044b. \\u0421 \\u0436\\u0438\\u0432\\u043e\\u0442\\u043d\\u044b\\u043c\\u0438 \\u043e\\u0441\\u043e\\u0431\\u0435\\u043d\\u043d\\u043e \\u043f\\u0440\\u043e\\u0431\\u043b\\u0435\\u043c\\u043d\\u043e, \\u0442\\u043e \\u043a\\u043e\\u0442\\u0430 \\u043d\\u0435 \\u0437\\u0430\\u043c\\u0435\\u0442\\u0438\\u0442, \\u0442\\u043e \\u0441\\u043e\\u0431\\u0430\\u043a\\u0443 \\u0432 \\u0446\\u0435\\u043d\\u0442\\u0440\\u0435 \\u043a\\u0430\\u0440\\u0442\\u0438\\u043d\\u043a\\u0438, \\u043d\\u043e \\u043f\\u0440\\u0435\\u0434\\u043c\\u0435\\u0442\\u044b \\u0438\\u043d\\u0442\\u0435\\u0440\\u044c\\u0435\\u0440\\u0430 \\u0438 \\u0433\\u043e\\u0440\\u043e\\u0434\\u0441\\u043a\\u0438\\u0435 \\u0441\\u0446\\u0435\\u043d\\u044b \\u043e\\u0442\\u043b\\u0438\\u0447\\u043d\\u043e.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{},"execution_count":2}],"source":["import pandas as pd\n","\n","# Данные для сравнения\n","data = {\n","    \"Алгоритм / Библиотека\": [\n","        \"YOLO11n-Seg (Ultralytics)\",\n","        \"MMSegmentation (PSPNet, ADE20K)\",\n","        \"Segmentation Models PyTorch (SMP)\",\n","        \"Detectron2\",\n","        \"Torchvision FCN\",\n","        \"Torchvision DeepLab v3\",\n","        \"Torchvision Mask R-CNN\",\n","        \"OpenCV (GrabCut/Watershed)\"\n","    ],\n","    \"Скорость\": [\n","        \"Очень высокая (реальное время)\",\n","        \"Средняя\",\n","        \"Средняя–высокая\",\n","        \"Средняя\",\n","        \"Средняя\",\n","        \"Средняя\",\n","        \"Низкая–средняя\",\n","        \"Высокая (но простые методы)\"\n","    ],\n","    \"Датасет обучения\": [\n","        \"COCO\",\n","        \"ADE20K\",\n","        \"Разные (ImageNet, COCO, Cityscapes)\",\n","        \"COCO\",\n","        \"COCO\",\n","        \"COCO\",\n","        \"COCO\",\n","        \"Нет (алгоритмы без предобучения)\"\n","    ],\n","    \"Кол-во классов\": [\n","        \"80\",\n","        \"150\",\n","        \"Зависит от модели (до 150+)\",\n","        \"80+\",\n","        \"21 (VOC), 80 (COCO)\",\n","        \"21 (VOC), 80 (COCO)\",\n","        \"80+\",\n","        \"Ограничено (2–5)\"\n","    ],\n","    \"Лучшие сценарии\": [\n","        \"Видео, камеры, потоковые данные\",\n","        \"Городские сцены, интерьер\",\n","        \"Гибкая настройка под медицину, дороги, объекты\",\n","        \"Instance segmentation, сложные сцены\",\n","        \"Базовая семантическая сегментация\",\n","        \"Городские сцены, дороги\",\n","        \"Instance segmentation (объекты в сценах)\",\n","        \"Простая сегментация, фон/объект\"\n","    ],\n","    \"Точность (mIoU/mAP)\": [\n","        \"mAP ~50–53%\",\n","        \"mIoU ~43% (ADE20K)\",\n","        \"До 0.9 IoU (на мед. данных)\",\n","        \"mAP ~37–40%\",\n","        \"mIoU ~62% (VOC)\",\n","        \"mIoU ~82% (Cityscapes)\",\n","        \"mAP ~37–40%\",\n","        \"Зависит от задачи, обычно низкая\"\n","    ],\n","    \"Макс. объектов на картинке\": [\n","        \"Сотни\",\n","        \"Десятки–сотни\",\n","        \"Десятки\",\n","        \"Сотни\",\n","        \"Десятки\",\n","        \"Десятки\",\n","        \"Сотни\",\n","        \"Ограничено\"\n","    ],\n","    \"Личные наблюдения\": [\n","        \"Быстро, просто, но не так точно, как хотелось бы. С животными особенно проблемно, то кота не заметит, то собаку в центре картинки, но предметы интерьера и городские сцены отлично.\",\n","        \"- (проблема с зависимостями в GoogleCollab)\",\n","        \"Нет предобученных весов, нужно подбирать датасет и обучать самостоятельно\",\n","        \"Медленнее YOLO, но очень хорошо сегментирует, выдаёт высокие степени уверенности, работает круто и на городских сценах, и на интерьерах, и вообще мелкие детали находит аккуратненько выделяет\",\n","        \"Небыстро, но с задачей справляется, хоть и с небольшими погрешностями.\",\n","        \"Небыстро, путает мелкие предметы, отлично справляется с городскими пейзажами, проезжей частью\",\n","        \"Небыстро, но с задачей справляется.\",\n","        \"Плохо справляется, делит на объект/фон. Нет предобученной модели, базовые алгоритмы. Быстро и некачественно)))\"\n","    ]\n","}\n","\n","# Создание таблицы\n","df = pd.DataFrame(data)\n","\n","# Отображение таблицы\n","df\n"]},{"cell_type":"markdown","source":["Топ-2: Detectron2 (все картинки, которые давала, сегментировал на отлично), YOLO для видео, да и на картинках относительно хорошо."],"metadata":{"id":"VYhE6jSxJEl2"}}]}