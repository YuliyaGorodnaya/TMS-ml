{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Задание: бинарная классификация - определить в аудио говорят Barbie или Puppy??? Данных мало -> необходима аугментация"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting audiomentations\n",
      "  Downloading audiomentations-0.43.1-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: numpy<3,>=1.22.0 in d:\\anaconda3\\lib\\site-packages (from audiomentations) (2.3.5)\n",
      "Collecting numpy-minmax<1,>=0.3.0 (from audiomentations)\n",
      "  Downloading numpy_minmax-0.5.0-cp313-cp313-win_amd64.whl.metadata (4.1 kB)\n",
      "Collecting numpy-rms<1,>=0.4.2 (from audiomentations)\n",
      "  Downloading numpy_rms-0.6.0-cp313-cp313-win_amd64.whl.metadata (3.6 kB)\n",
      "Requirement already satisfied: librosa!=0.10.0,<0.12.0,>=0.8.0 in d:\\anaconda3\\lib\\site-packages (from audiomentations) (0.11.0)\n",
      "Collecting python-stretch<1,>=0.3.1 (from audiomentations)\n",
      "  Downloading python_stretch-0.3.1-cp312-abi3-win_amd64.whl.metadata (3.7 kB)\n",
      "Requirement already satisfied: scipy<2,>=1.4 in d:\\anaconda3\\lib\\site-packages (from audiomentations) (1.16.3)\n",
      "Collecting soxr<1.0.0,>=0.3.2 (from audiomentations)\n",
      "  Downloading soxr-0.5.0.post1-cp312-abi3-win_amd64.whl.metadata (5.6 kB)\n",
      "Requirement already satisfied: audioread>=2.1.9 in d:\\anaconda3\\lib\\site-packages (from librosa!=0.10.0,<0.12.0,>=0.8.0->audiomentations) (3.1.0)\n",
      "Requirement already satisfied: numba>=0.51.0 in d:\\anaconda3\\lib\\site-packages (from librosa!=0.10.0,<0.12.0,>=0.8.0->audiomentations) (0.62.1)\n",
      "Requirement already satisfied: scikit-learn>=1.1.0 in d:\\anaconda3\\lib\\site-packages (from librosa!=0.10.0,<0.12.0,>=0.8.0->audiomentations) (1.7.2)\n",
      "Requirement already satisfied: joblib>=1.0 in d:\\anaconda3\\lib\\site-packages (from librosa!=0.10.0,<0.12.0,>=0.8.0->audiomentations) (1.5.2)\n",
      "Requirement already satisfied: decorator>=4.3.0 in d:\\anaconda3\\lib\\site-packages (from librosa!=0.10.0,<0.12.0,>=0.8.0->audiomentations) (5.2.1)\n",
      "Requirement already satisfied: soundfile>=0.12.1 in d:\\anaconda3\\lib\\site-packages (from librosa!=0.10.0,<0.12.0,>=0.8.0->audiomentations) (0.13.1)\n",
      "Requirement already satisfied: pooch>=1.1 in d:\\anaconda3\\lib\\site-packages (from librosa!=0.10.0,<0.12.0,>=0.8.0->audiomentations) (1.9.0)\n",
      "Requirement already satisfied: typing_extensions>=4.1.1 in d:\\anaconda3\\lib\\site-packages (from librosa!=0.10.0,<0.12.0,>=0.8.0->audiomentations) (4.15.0)\n",
      "Requirement already satisfied: lazy_loader>=0.1 in d:\\anaconda3\\lib\\site-packages (from librosa!=0.10.0,<0.12.0,>=0.8.0->audiomentations) (0.4)\n",
      "Requirement already satisfied: msgpack>=1.0 in d:\\anaconda3\\lib\\site-packages (from librosa!=0.10.0,<0.12.0,>=0.8.0->audiomentations) (1.1.1)\n",
      "Requirement already satisfied: standard-aifc in d:\\anaconda3\\lib\\site-packages (from librosa!=0.10.0,<0.12.0,>=0.8.0->audiomentations) (3.13.0)\n",
      "Requirement already satisfied: standard-sunau in d:\\anaconda3\\lib\\site-packages (from librosa!=0.10.0,<0.12.0,>=0.8.0->audiomentations) (3.13.0)\n",
      "Requirement already satisfied: cffi>=1.0.0 in d:\\anaconda3\\lib\\site-packages (from numpy-minmax<1,>=0.3.0->audiomentations) (2.0.0)\n",
      "Requirement already satisfied: pycparser in d:\\anaconda3\\lib\\site-packages (from cffi>=1.0.0->numpy-minmax<1,>=0.3.0->audiomentations) (2.23)\n",
      "Requirement already satisfied: packaging in d:\\anaconda3\\lib\\site-packages (from lazy_loader>=0.1->librosa!=0.10.0,<0.12.0,>=0.8.0->audiomentations) (25.0)\n",
      "Requirement already satisfied: llvmlite<0.46,>=0.45.0dev0 in d:\\anaconda3\\lib\\site-packages (from numba>=0.51.0->librosa!=0.10.0,<0.12.0,>=0.8.0->audiomentations) (0.45.1)\n",
      "Requirement already satisfied: platformdirs>=2.5.0 in d:\\anaconda3\\lib\\site-packages (from pooch>=1.1->librosa!=0.10.0,<0.12.0,>=0.8.0->audiomentations) (4.5.0)\n",
      "Requirement already satisfied: requests>=2.19.0 in d:\\anaconda3\\lib\\site-packages (from pooch>=1.1->librosa!=0.10.0,<0.12.0,>=0.8.0->audiomentations) (2.32.5)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in d:\\anaconda3\\lib\\site-packages (from requests>=2.19.0->pooch>=1.1->librosa!=0.10.0,<0.12.0,>=0.8.0->audiomentations) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\anaconda3\\lib\\site-packages (from requests>=2.19.0->pooch>=1.1->librosa!=0.10.0,<0.12.0,>=0.8.0->audiomentations) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\anaconda3\\lib\\site-packages (from requests>=2.19.0->pooch>=1.1->librosa!=0.10.0,<0.12.0,>=0.8.0->audiomentations) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\anaconda3\\lib\\site-packages (from requests>=2.19.0->pooch>=1.1->librosa!=0.10.0,<0.12.0,>=0.8.0->audiomentations) (2026.1.4)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in d:\\anaconda3\\lib\\site-packages (from scikit-learn>=1.1.0->librosa!=0.10.0,<0.12.0,>=0.8.0->audiomentations) (3.5.0)\n",
      "Requirement already satisfied: standard-chunk in d:\\anaconda3\\lib\\site-packages (from standard-aifc->librosa!=0.10.0,<0.12.0,>=0.8.0->audiomentations) (3.13.0)\n",
      "Requirement already satisfied: audioop-lts in d:\\anaconda3\\lib\\site-packages (from standard-aifc->librosa!=0.10.0,<0.12.0,>=0.8.0->audiomentations) (0.2.2)\n",
      "Downloading audiomentations-0.43.1-py3-none-any.whl (86 kB)\n",
      "Downloading numpy_minmax-0.5.0-cp313-cp313-win_amd64.whl (14 kB)\n",
      "Downloading numpy_rms-0.6.0-cp313-cp313-win_amd64.whl (13 kB)\n",
      "Downloading python_stretch-0.3.1-cp312-abi3-win_amd64.whl (97 kB)\n",
      "Downloading soxr-0.5.0.post1-cp312-abi3-win_amd64.whl (164 kB)\n",
      "Installing collected packages: soxr, python-stretch, numpy-rms, numpy-minmax, audiomentations\n",
      "\n",
      "  Attempting uninstall: soxr\n",
      "\n",
      "    Found existing installation: soxr 1.0.0\n",
      "\n",
      "    Uninstalling soxr-1.0.0:\n",
      "\n",
      "      Successfully uninstalled soxr-1.0.0\n",
      "\n",
      "   ---------------------------------------- 0/5 [soxr]\n",
      "   -------- ------------------------------- 1/5 [python-stretch]\n",
      "   ------------------------ --------------- 3/5 [numpy-minmax]\n",
      "   -------------------------------- ------- 4/5 [audiomentations]\n",
      "   -------------------------------- ------- 4/5 [audiomentations]\n",
      "   -------------------------------- ------- 4/5 [audiomentations]\n",
      "   -------------------------------- ------- 4/5 [audiomentations]\n",
      "   -------------------------------- ------- 4/5 [audiomentations]\n",
      "   -------------------------------- ------- 4/5 [audiomentations]\n",
      "   ---------------------------------------- 5/5 [audiomentations]\n",
      "\n",
      "Successfully installed audiomentations-0.43.1 numpy-minmax-0.5.0 numpy-rms-0.6.0 python-stretch-0.3.1 soxr-0.5.0.post1\n"
     ]
    }
   ],
   "source": [
    "!pip install audiomentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting kagglehub\n",
      "  Downloading kagglehub-0.4.3-py3-none-any.whl.metadata (40 kB)\n",
      "Collecting kagglesdk<1.0,>=0.1.14 (from kagglehub)\n",
      "  Downloading kagglesdk-0.1.15-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: packaging in d:\\anaconda3\\lib\\site-packages (from kagglehub) (25.0)\n",
      "Requirement already satisfied: pyyaml in d:\\anaconda3\\lib\\site-packages (from kagglehub) (6.0.3)\n",
      "Requirement already satisfied: requests in d:\\anaconda3\\lib\\site-packages (from kagglehub) (2.32.5)\n",
      "Requirement already satisfied: tqdm in d:\\anaconda3\\lib\\site-packages (from kagglehub) (4.67.1)\n",
      "Requirement already satisfied: protobuf in d:\\anaconda3\\lib\\site-packages (from kagglesdk<1.0,>=0.1.14->kagglehub) (5.29.3)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in d:\\anaconda3\\lib\\site-packages (from requests->kagglehub) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\anaconda3\\lib\\site-packages (from requests->kagglehub) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\anaconda3\\lib\\site-packages (from requests->kagglehub) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\anaconda3\\lib\\site-packages (from requests->kagglehub) (2026.1.4)\n",
      "Requirement already satisfied: colorama in d:\\anaconda3\\lib\\site-packages (from tqdm->kagglehub) (0.4.6)\n",
      "Downloading kagglehub-0.4.3-py3-none-any.whl (70 kB)\n",
      "Downloading kagglesdk-0.1.15-py3-none-any.whl (160 kB)\n",
      "Installing collected packages: kagglesdk, kagglehub\n",
      "\n",
      "   ---------------------------------------- 0/2 [kagglesdk]\n",
      "   ---------------------------------------- 0/2 [kagglesdk]\n",
      "   ---------------------------------------- 0/2 [kagglesdk]\n",
      "   ---------------------------------------- 0/2 [kagglesdk]\n",
      "   ---------------------------------------- 0/2 [kagglesdk]\n",
      "   ---------------------------------------- 0/2 [kagglesdk]\n",
      "   ---------------------------------------- 0/2 [kagglesdk]\n",
      "   ---------------------------------------- 0/2 [kagglesdk]\n",
      "   ---------------------------------------- 0/2 [kagglesdk]\n",
      "   ---------------------------------------- 0/2 [kagglesdk]\n",
      "   ---------------------------------------- 0/2 [kagglesdk]\n",
      "   ---------------------------------------- 0/2 [kagglesdk]\n",
      "   -------------------- ------------------- 1/2 [kagglehub]\n",
      "   -------------------- ------------------- 1/2 [kagglehub]\n",
      "   -------------------- ------------------- 1/2 [kagglehub]\n",
      "   -------------------- ------------------- 1/2 [kagglehub]\n",
      "   ---------------------------------------- 2/2 [kagglehub]\n",
      "\n",
      "Successfully installed kagglehub-0.4.3 kagglesdk-0.1.15\n"
     ]
    }
   ],
   "source": [
    "!pip install kagglehub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import librosa\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import audiomentations as A\n",
    "\n",
    "import pickle # сериализация/десериализация\n",
    "import kagglehub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading to C:\\Users\\Юлия Городная\\.cache\\kagglehub\\datasets\\levshaazz\\audio-binary-classification-barbie-vs-puppy\\1.archive...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 15.6M/15.6M [00:02<00:00, 6.03MB/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting files...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "path = kagglehub.dataset_download(\"levshaazz/audio-binary-classification-barbie-vs-puppy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "barbie_folder = path + r\"\\\\barbie_vs_puppy\\\\barbie\"\n",
    "puppy_folder = path + r\"\\\\barbie_vs_puppy\\\\puppy\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "barbie_files = [os.path.join(barbie_folder, f) for f in os.listdir(barbie_folder) if f.endswith('.wav')]\n",
    "puppy_files = [os.path.join(puppy_folder, f) for f in os.listdir(puppy_folder) if f.endswith('.wav')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Barbie: 50\n",
      "Puppy: 48\n"
     ]
    }
   ],
   "source": [
    "print(f\"Barbie: {len(barbie_files)}\")\n",
    "print(f\"Puppy: {len(puppy_files)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "augment = A.Compose([\n",
    "    A.AddGaussianNoise(min_amplitude=0.001, max_amplitude=0.005, p=0.3),\n",
    "    A.TimeStretch(min_rate=0.9, max_rate=1.1, p=0.3),\n",
    "    A.PitchShift(min_semitones=-2, max_semitones=2, p=0.3),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Получаем фичи для обучения классификатора\n",
    "def extract_features(file_path, apply_augmentation=False):\n",
    "    audio, sr = librosa.load(file_path, sr=22050, duration=3.0)\n",
    "    \n",
    "    if apply_augmentation:\n",
    "        audio = augment(samples=audio, sample_rate=sr)\n",
    "    \n",
    "    mfcc = librosa.feature.mfcc(y=audio, sr=sr, n_mfcc=13)\n",
    "    mfcc_mean = np.mean(mfcc, axis=1)\n",
    "    \n",
    "    mel = librosa.feature.melspectrogram(y=audio, sr=sr, n_mels=40)\n",
    "    mel_mean = np.mean(mel, axis=1)\n",
    "    \n",
    "    features = np.concatenate([mfcc_mean, mel_mean])\n",
    "    \n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_list = []\n",
    "y_list = []\n",
    "file_paths = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Загружаем Barbie аудио\n",
    "for file in barbie_files:\n",
    "    features = extract_features(file, apply_augmentation=False)\n",
    "    X_list.append(features)\n",
    "    y_list.append(0)\n",
    "    file_paths.append(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Загружаем Puppy аудио\n",
    "for file in puppy_files:\n",
    "    features = extract_features(file, apply_augmentation=False)\n",
    "    X_list.append(features)\n",
    "    y_list.append(1)\n",
    "    file_paths.append(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(X_list)\n",
    "y = np.array(y_list)\n",
    "file_paths = np.array(file_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 58\n",
      "Val: 20\n",
      "Test: 20\n"
     ]
    }
   ],
   "source": [
    "# Split (train, val, test)\n",
    "indices = np.arange(len(X))\n",
    "\n",
    "idx_temp, idx_test = train_test_split(indices, test_size=0.2, random_state=42, stratify=y)\n",
    "idx_train, idx_val = train_test_split(idx_temp, test_size=0.25, random_state=42, stratify=y[idx_temp])\n",
    "\n",
    "X_train = X[idx_train]\n",
    "y_train = y[idx_train]\n",
    "files_train = file_paths[idx_train]\n",
    "\n",
    "X_val = X[idx_val]\n",
    "y_val = y[idx_val]\n",
    "\n",
    "X_test = X[idx_test]\n",
    "y_test = y[idx_test]\n",
    "\n",
    "print(f\"Train: {len(X_train)}\")\n",
    "print(f\"Val: {len(X_val)}\")\n",
    "print(f\"Test: {len(X_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train после аугментации: 348\n"
     ]
    }
   ],
   "source": [
    "# Увеличиваем обучающую выборку\n",
    "X_train_aug = []\n",
    "y_train_aug = []\n",
    "\n",
    "for file_path in files_train:\n",
    "    for _ in range(5):\n",
    "        features = extract_features(file_path, apply_augmentation=True)\n",
    "        X_train_aug.append(features)\n",
    "        idx = np.where(file_paths == file_path)[0][0]\n",
    "        y_train_aug.append(y[idx])\n",
    "\n",
    "X_train_combined = np.vstack([X_train, np.array(X_train_aug)])\n",
    "y_train_combined = np.concatenate([y_train, np.array(y_train_aug)])\n",
    "\n",
    "print(f\"Train после аугментации: {len(X_train_combined)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Нормализация\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train_combined)\n",
    "X_val_scaled = scaler.transform(X_val)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(input_shape):\n",
    "    model = keras.Sequential([\n",
    "        layers.Input(shape=(input_shape,)),\n",
    "        layers.Dense(64, activation='relu'),\n",
    "        layers.Dropout(0.5),\n",
    "        layers.Dense(32, activation='relu'),\n",
    "        layers.Dropout(0.5),\n",
    "        layers.Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.5057 - loss: 0.8018 - val_accuracy: 0.4500 - val_loss: 0.7014 - learning_rate: 0.0010\n",
      "Epoch 2/100\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6034 - loss: 0.6898 - val_accuracy: 0.6000 - val_loss: 0.6435 - learning_rate: 0.0010\n",
      "Epoch 3/100\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6379 - loss: 0.6006 - val_accuracy: 0.7500 - val_loss: 0.6155 - learning_rate: 0.0010\n",
      "Epoch 4/100\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7155 - loss: 0.5083 - val_accuracy: 0.7500 - val_loss: 0.5914 - learning_rate: 0.0010\n",
      "Epoch 5/100\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7299 - loss: 0.5152 - val_accuracy: 0.7500 - val_loss: 0.5705 - learning_rate: 0.0010\n",
      "Epoch 6/100\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7644 - loss: 0.4370 - val_accuracy: 0.6500 - val_loss: 0.5547 - learning_rate: 0.0010\n",
      "Epoch 7/100\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7902 - loss: 0.4325 - val_accuracy: 0.7500 - val_loss: 0.5390 - learning_rate: 0.0010\n",
      "Epoch 8/100\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7960 - loss: 0.4243 - val_accuracy: 0.7500 - val_loss: 0.5294 - learning_rate: 0.0010\n",
      "Epoch 9/100\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8218 - loss: 0.3814 - val_accuracy: 0.7500 - val_loss: 0.5244 - learning_rate: 0.0010\n",
      "Epoch 10/100\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8563 - loss: 0.3274 - val_accuracy: 0.7500 - val_loss: 0.5355 - learning_rate: 0.0010\n",
      "Epoch 11/100\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8966 - loss: 0.2932 - val_accuracy: 0.7500 - val_loss: 0.5477 - learning_rate: 0.0010\n",
      "Epoch 12/100\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8621 - loss: 0.2881 - val_accuracy: 0.7500 - val_loss: 0.5696 - learning_rate: 0.0010\n",
      "Epoch 13/100\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8793 - loss: 0.2677 - val_accuracy: 0.7500 - val_loss: 0.5908 - learning_rate: 0.0010\n",
      "Epoch 14/100\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8563 - loss: 0.2811 - val_accuracy: 0.7500 - val_loss: 0.5669 - learning_rate: 0.0010\n",
      "Epoch 15/100\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9109 - loss: 0.2360 - val_accuracy: 0.7500 - val_loss: 0.5772 - learning_rate: 5.0000e-04\n",
      "Epoch 16/100\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9109 - loss: 0.2314 - val_accuracy: 0.7000 - val_loss: 0.6001 - learning_rate: 5.0000e-04\n",
      "Epoch 17/100\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9167 - loss: 0.2189 - val_accuracy: 0.7000 - val_loss: 0.6254 - learning_rate: 5.0000e-04\n",
      "Epoch 18/100\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9109 - loss: 0.2038 - val_accuracy: 0.7000 - val_loss: 0.6466 - learning_rate: 5.0000e-04\n",
      "Epoch 19/100\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9195 - loss: 0.2201 - val_accuracy: 0.7500 - val_loss: 0.6408 - learning_rate: 5.0000e-04\n",
      "Epoch 20/100\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9282 - loss: 0.2040 - val_accuracy: 0.7500 - val_loss: 0.6560 - learning_rate: 2.5000e-04\n",
      "Epoch 21/100\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9397 - loss: 0.1871 - val_accuracy: 0.7000 - val_loss: 0.6721 - learning_rate: 2.5000e-04\n",
      "Epoch 22/100\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9167 - loss: 0.2014 - val_accuracy: 0.7000 - val_loss: 0.6926 - learning_rate: 2.5000e-04\n",
      "Epoch 23/100\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9253 - loss: 0.1979 - val_accuracy: 0.7000 - val_loss: 0.7038 - learning_rate: 2.5000e-04\n",
      "Epoch 24/100\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8994 - loss: 0.1901 - val_accuracy: 0.7000 - val_loss: 0.7201 - learning_rate: 2.5000e-04\n"
     ]
    }
   ],
   "source": [
    "model = build_model(X_train_scaled.shape[1])\n",
    "\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=0.001),\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "early_stop = keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=15,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "reduce_lr = keras.callbacks.ReduceLROnPlateau(\n",
    "    monitor='val_loss',\n",
    "    factor=0.5,\n",
    "    patience=5,\n",
    "    min_lr=0.00001\n",
    ")\n",
    "\n",
    "history = model.fit(\n",
    "    X_train_scaled, y_train_combined,\n",
    "    validation_data=(X_val_scaled, y_val),\n",
    "    epochs=100,\n",
    "    batch_size=8,\n",
    "    callbacks=[early_stop, reduce_lr],\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ИТОГО: на train - accuracy= 0.9368, на val - 0,7346."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 0.9052\n",
      "Val Accuracy:   0.7000\n",
      "Test Accuracy:  0.8000\n"
     ]
    }
   ],
   "source": [
    "train_loss, train_acc = model.evaluate(X_train_scaled, y_train_combined, verbose=0)\n",
    "val_loss, val_acc = model.evaluate(X_val_scaled, y_val, verbose=0)\n",
    "test_loss, test_acc = model.evaluate(X_test_scaled, y_test, verbose=0)\n",
    "\n",
    "print(f\"Train Accuracy: {train_acc:.4f}\")\n",
    "print(f\"Val Accuracy:   {val_acc:.4f}\")\n",
    "print(f\"Test Accuracy:  {test_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_audio(file_path, model, scaler):\n",
    "    features = extract_features(file_path, apply_augmentation=False)\n",
    "    features = features.reshape(1, -1)\n",
    "    features_scaled = scaler.transform(features)\n",
    "    prediction = model.predict(features_scaled, verbose=0)[0][0]\n",
    "    \n",
    "    if prediction > 0.5:\n",
    "        return \"I hear Puppy\", prediction\n",
    "    else:\n",
    "        return \"I hear Barbie\", 1 - prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Файл: barbie_0.wav\n",
      "Предсказание: I hear Barbie\n",
      "Уверенность: 77.14%\n"
     ]
    }
   ],
   "source": [
    "# Проверка предсказания на файле из исходного датасета\n",
    "test_file = barbie_files[0]\n",
    "label, confidence = predict_audio(test_file, model, scaler)\n",
    "print(f\"Файл: {os.path.basename(test_file)}\")\n",
    "print(f\"Предсказание: {label}\")\n",
    "print(f\"Уверенность: {confidence:.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Файл: puppy.wav\n",
      "Предсказание: I hear Puppy\n",
      "Уверенность: 75.93%\n"
     ]
    }
   ],
   "source": [
    "file_path = '../data/puppy.wav'\n",
    "\n",
    "label, confidence = predict_audio(file_path, model, scaler)\n",
    "\n",
    "print(f\"Файл: {os.path.basename(file_path)}\")\n",
    "print(f\"Предсказание: {label}\")\n",
    "print(f\"Уверенность: {confidence:.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Файл: barbie.wav\n",
      "Предсказание: I hear Barbie\n",
      "Уверенность: 53.17%\n"
     ]
    }
   ],
   "source": [
    "file_path = '../data/barbie.wav'\n",
    "\n",
    "label, confidence = predict_audio(file_path, model, scaler)\n",
    "\n",
    "print(f\"Файл: {os.path.basename(file_path)}\")\n",
    "print(f\"Предсказание: {label}\")\n",
    "print(f\"Уверенность: {confidence:.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Уверенность в ответах не самая высокая (53,17 - почти угадывание), думаю, 300 сэмплов - всё ещё очень маленький датасет для обучения, нужно сделать ещё больше тренировочных данных для обучения модели."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
