{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyNptMKEJhBzcrX/ZpMeezvr"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torchvision import transforms, models\n","from torchvision.datasets import ImageFolder\n","from torch.utils.data import DataLoader, random_split\n","from tqdm import tqdm\n","import os\n","import kagglehub"],"metadata":{"id":"P3YEjybtJRuz","executionInfo":{"status":"ok","timestamp":1762180833711,"user_tz":-180,"elapsed":13553,"user":{"displayName":"Юлия Гор.","userId":"08838257762277085118"}}},"execution_count":1,"outputs":[]},{"cell_type":"code","source":["# 1. Загрузка датасета\n","path = kagglehub.dataset_download(\"imbikramsaha/food11\")\n","data_dir = os.path.join(path, \"food11\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"C7SoJbl0JTlD","executionInfo":{"status":"ok","timestamp":1762180868213,"user_tz":-180,"elapsed":34507,"user":{"displayName":"Юлия Гор.","userId":"08838257762277085118"}},"outputId":"ac8ee507-e1e4-47a6-e2e0-5108a1d60e7b"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading from https://www.kaggle.com/api/v1/datasets/download/imbikramsaha/food11?dataset_version_number=1...\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 519M/519M [00:24<00:00, 22.4MB/s]"]},{"output_type":"stream","name":"stdout","text":["Extracting files...\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}]},{"cell_type":"code","source":["# 2. Настройка устройства\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"],"metadata":{"id":"Co-IWgYVJWFe","executionInfo":{"status":"ok","timestamp":1762180868257,"user_tz":-180,"elapsed":19,"user":{"displayName":"Юлия Гор.","userId":"08838257762277085118"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["# 3. Размеры входа для каждой модели\n","input_sizes = {\"b0\": 224, \"b1\": 240, \"b2\": 260}"],"metadata":{"id":"2CPGku1nJaeE","executionInfo":{"status":"ok","timestamp":1762180868266,"user_tz":-180,"elapsed":4,"user":{"displayName":"Юлия Гор.","userId":"08838257762277085118"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["# 4. Функция подготовки данных\n","def get_dataloaders(input_size):\n","    transform = transforms.Compose([\n","        transforms.Resize((input_size, input_size)),\n","        transforms.ToTensor(),\n","        transforms.Normalize(mean=[0.485, 0.456, 0.406],\n","                             std=[0.229, 0.224, 0.225])\n","    ])\n","    dataset = ImageFolder(root=data_dir, transform=transform)\n","    num_classes = len(dataset.classes)\n","    train_size = int(0.8 * len(dataset))\n","    val_size = len(dataset) - train_size\n","    train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n","    train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n","    val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n","    return train_loader, val_loader, num_classes"],"metadata":{"id":"NVhxNAhsJcoE","executionInfo":{"status":"ok","timestamp":1762180868286,"user_tz":-180,"elapsed":6,"user":{"displayName":"Юлия Гор.","userId":"08838257762277085118"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["# 5. Функция создания модели\n","def get_efficientnet(version: str, num_classes: int):\n","    if version == \"b0\":\n","        model = models.efficientnet_b0(pretrained=True)\n","    elif version == \"b1\":\n","        model = models.efficientnet_b1(pretrained=True)\n","    elif version == \"b2\":\n","        model = models.efficientnet_b2(pretrained=True)\n","    else:\n","        raise ValueError(\"Unknown EfficientNet version\")\n","    model.classifier[1] = nn.Linear(model.classifier[1].in_features, num_classes)\n","    return model.to(device)"],"metadata":{"id":"uX3ahT8cJgfb","executionInfo":{"status":"ok","timestamp":1762180868292,"user_tz":-180,"elapsed":2,"user":{"displayName":"Юлия Гор.","userId":"08838257762277085118"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["# 6. Функции обучения и оценки\n","def train_epoch(model, loader, criterion, optimizer):\n","    model.train()\n","    running_loss = 0.0\n","    loop = tqdm(loader, desc=\"Training\", leave=False)\n","    for inputs, targets in loop:\n","        inputs, targets = inputs.to(device), targets.to(device)\n","        optimizer.zero_grad()\n","        outputs = model(inputs)\n","        loss = criterion(outputs, targets)\n","        loss.backward()\n","        optimizer.step()\n","        running_loss += loss.item()\n","        loop.set_postfix(loss=loss.item())\n","    return running_loss / len(loader)\n","\n","def evaluate(model, loader):\n","    model.eval()\n","    correct = 0\n","    total = 0\n","    with torch.no_grad():\n","        for inputs, targets in loader:\n","            inputs, targets = inputs.to(device), targets.to(device)\n","            outputs = model(inputs)\n","            _, preds = torch.max(outputs, 1)\n","            correct += (preds == targets).sum().item()\n","            total += targets.size(0)\n","    return 100 * correct / total"],"metadata":{"id":"qw_ppAdvJkt2","executionInfo":{"status":"ok","timestamp":1762180868297,"user_tz":-180,"elapsed":2,"user":{"displayName":"Юлия Гор.","userId":"08838257762277085118"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["# 7. Цикл обучения и сравнения\n","criterion = nn.CrossEntropyLoss()\n","results = {}\n","\n","for version in [\"b0\", \"b1\", \"b2\"]:\n","    print(f\"\\n Обучение EfficientNet-{version.upper()}\")\n","    input_size = input_sizes[version]\n","    train_loader, val_loader, num_classes = get_dataloaders(input_size)\n","    model = get_efficientnet(version, num_classes)\n","    optimizer = optim.Adam(model.parameters(), lr=1e-4)\n","\n","    for epoch in range(5):  # можно увеличить до 10\n","        print(f\"Epoch {epoch+1}/5\")\n","        train_loss = train_epoch(model, train_loader, criterion, optimizer)\n","        val_acc = evaluate(model, val_loader)\n","        print(f\"Loss: {train_loss:.4f} | Val Acc: {val_acc:.2f}%\")\n","\n","    results[version] = val_acc"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QE0tCFV0JpEk","executionInfo":{"status":"ok","timestamp":1762182753628,"user_tz":-180,"elapsed":1885326,"user":{"displayName":"Юлия Гор.","userId":"08838257762277085118"}},"outputId":"8f176633-b4f2-474a-dae3-08399540863b"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n","  warnings.warn(\n","/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=EfficientNet_B0_Weights.IMAGENET1K_V1`. You can also use `weights=EfficientNet_B0_Weights.DEFAULT` to get the most up-to-date weights.\n","  warnings.warn(msg)\n"]},{"output_type":"stream","name":"stdout","text":["\n"," Обучение EfficientNet-B0\n","Downloading: \"https://download.pytorch.org/models/efficientnet_b0_rwightman-7f5810bc.pth\" to /root/.cache/torch/hub/checkpoints/efficientnet_b0_rwightman-7f5810bc.pth\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 20.5M/20.5M [00:00<00:00, 202MB/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/5\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["Loss: 0.3536 | Val Acc: 89.95%\n","Epoch 2/5\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["Loss: 0.2374 | Val Acc: 89.64%\n","Epoch 3/5\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["Loss: 0.1519 | Val Acc: 88.14%\n","Epoch 4/5\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["Loss: 0.0784 | Val Acc: 88.23%\n","Epoch 5/5\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=EfficientNet_B1_Weights.IMAGENET1K_V1`. You can also use `weights=EfficientNet_B1_Weights.DEFAULT` to get the most up-to-date weights.\n","  warnings.warn(msg)\n"]},{"output_type":"stream","name":"stdout","text":["Loss: 0.0457 | Val Acc: 86.73%\n","\n"," Обучение EfficientNet-B1\n","Downloading: \"https://download.pytorch.org/models/efficientnet_b1_rwightman-bac287d4.pth\" to /root/.cache/torch/hub/checkpoints/efficientnet_b1_rwightman-bac287d4.pth\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 30.1M/30.1M [00:00<00:00, 90.1MB/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/5\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["Loss: 0.3458 | Val Acc: 90.36%\n","Epoch 2/5\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["Loss: 0.2333 | Val Acc: 89.95%\n","Epoch 3/5\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["Loss: 0.1309 | Val Acc: 87.50%\n","Epoch 4/5\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["Loss: 0.0598 | Val Acc: 84.23%\n","Epoch 5/5\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=EfficientNet_B2_Weights.IMAGENET1K_V1`. You can also use `weights=EfficientNet_B2_Weights.DEFAULT` to get the most up-to-date weights.\n","  warnings.warn(msg)\n"]},{"output_type":"stream","name":"stdout","text":["Loss: 0.0319 | Val Acc: 86.27%\n","\n"," Обучение EfficientNet-B2\n","Downloading: \"https://download.pytorch.org/models/efficientnet_b2_rwightman-c35c1473.pth\" to /root/.cache/torch/hub/checkpoints/efficientnet_b2_rwightman-c35c1473.pth\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 35.2M/35.2M [00:00<00:00, 172MB/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/5\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["Loss: 0.3444 | Val Acc: 90.64%\n","Epoch 2/5\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["Loss: 0.2328 | Val Acc: 89.09%\n","Epoch 3/5\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["Loss: 0.1257 | Val Acc: 88.82%\n","Epoch 4/5\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["Loss: 0.0575 | Val Acc: 87.64%\n","Epoch 5/5\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["Loss: 0.0402 | Val Acc: 87.73%\n"]}]},{"cell_type":"code","execution_count":9,"metadata":{"id":"SHZ4Ly5HJJH_","executionInfo":{"status":"ok","timestamp":1762182753674,"user_tz":-180,"elapsed":69,"user":{"displayName":"Юлия Гор.","userId":"08838257762277085118"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"5fac2208-0530-495a-c69d-8eded2b6ee58"},"outputs":[{"output_type":"stream","name":"stdout","text":["\n"," Сравнение моделей:\n","EfficientNet-B0: 86.73% точность на валидации\n","EfficientNet-B1: 86.27% точность на валидации\n","EfficientNet-B2: 87.73% точность на валидации\n"]}],"source":["# 8. Вывод результатов\n","print(\"\\n Сравнение моделей:\")\n","for version, acc in results.items():\n","    print(f\"EfficientNet-{version.upper()}: {acc:.2f}% точность на валидации\")"]},{"cell_type":"markdown","source":["Как видим, модели хорошо справляются на тренировочных данных, но хуже справляются с тестовыми, что говорит о переобучении. Модель, которая обучалась на гораздо большем датасете и в приницпе очень мощная легко переобучается на небольшом датасете вроде нашего."],"metadata":{"id":"5SZwAYZqSngr"}}]}