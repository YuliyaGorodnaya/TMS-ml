{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b3bf24e2-a17f-49e9-bd80-9abf57f6a993",
   "metadata": {},
   "source": [
    "Загрузить предобработанные данные по item и user (по отдельности и вместе) и через генерацию промпта получить результат в виде:\n",
    "а) пользователей со схожими интересами\n",
    "б) рекомендованные фильмы\n",
    "\n",
    "perplexity ai api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "88f3dfa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f739a2aa-c601-4ee8-9885-7dbe6be28b6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import csr_matrix\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0c788d28-8616-43d1-914f-809d4246a09e",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting openai\n",
      "  Downloading openai-2.17.0-py3-none-any.whl.metadata (29 kB)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in d:\\anaconda3\\lib\\site-packages (from openai) (4.10.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in d:\\anaconda3\\lib\\site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in d:\\anaconda3\\lib\\site-packages (from openai) (0.28.1)\n",
      "Collecting jiter<1,>=0.10.0 (from openai)\n",
      "  Downloading jiter-0.13.0-cp313-cp313-win_amd64.whl.metadata (5.3 kB)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in d:\\anaconda3\\lib\\site-packages (from openai) (2.12.4)\n",
      "Requirement already satisfied: sniffio in d:\\anaconda3\\lib\\site-packages (from openai) (1.3.0)\n",
      "Requirement already satisfied: tqdm>4 in d:\\anaconda3\\lib\\site-packages (from openai) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in d:\\anaconda3\\lib\\site-packages (from openai) (4.15.0)\n",
      "Requirement already satisfied: idna>=2.8 in d:\\anaconda3\\lib\\site-packages (from anyio<5,>=3.5.0->openai) (3.11)\n",
      "Requirement already satisfied: certifi in d:\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (2026.1.4)\n",
      "Requirement already satisfied: httpcore==1.* in d:\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in d:\\anaconda3\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in d:\\anaconda3\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.5 in d:\\anaconda3\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (2.41.5)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in d:\\anaconda3\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (0.4.2)\n",
      "Requirement already satisfied: colorama in d:\\anaconda3\\lib\\site-packages (from tqdm>4->openai) (0.4.6)\n",
      "Downloading openai-2.17.0-py3-none-any.whl (1.1 MB)\n",
      "   ---------------------------------------- 0.0/1.1 MB ? eta -:--:--\n",
      "   --------- ------------------------------ 0.3/1.1 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.1/1.1 MB 3.7 MB/s  0:00:00\n",
      "Downloading jiter-0.13.0-cp313-cp313-win_amd64.whl (202 kB)\n",
      "Installing collected packages: jiter, openai\n",
      "\n",
      "   ---------------------------------------- 0/2 [jiter]\n",
      "   -------------------- ------------------- 1/2 [openai]\n",
      "   -------------------- ------------------- 1/2 [openai]\n",
      "   -------------------- ------------------- 1/2 [openai]\n",
      "   -------------------- ------------------- 1/2 [openai]\n",
      "   -------------------- ------------------- 1/2 [openai]\n",
      "   -------------------- ------------------- 1/2 [openai]\n",
      "   -------------------- ------------------- 1/2 [openai]\n",
      "   -------------------- ------------------- 1/2 [openai]\n",
      "   -------------------- ------------------- 1/2 [openai]\n",
      "   -------------------- ------------------- 1/2 [openai]\n",
      "   -------------------- ------------------- 1/2 [openai]\n",
      "   -------------------- ------------------- 1/2 [openai]\n",
      "   -------------------- ------------------- 1/2 [openai]\n",
      "   -------------------- ------------------- 1/2 [openai]\n",
      "   -------------------- ------------------- 1/2 [openai]\n",
      "   -------------------- ------------------- 1/2 [openai]\n",
      "   -------------------- ------------------- 1/2 [openai]\n",
      "   -------------------- ------------------- 1/2 [openai]\n",
      "   -------------------- ------------------- 1/2 [openai]\n",
      "   -------------------- ------------------- 1/2 [openai]\n",
      "   -------------------- ------------------- 1/2 [openai]\n",
      "   -------------------- ------------------- 1/2 [openai]\n",
      "   -------------------- ------------------- 1/2 [openai]\n",
      "   -------------------- ------------------- 1/2 [openai]\n",
      "   -------------------- ------------------- 1/2 [openai]\n",
      "   -------------------- ------------------- 1/2 [openai]\n",
      "   -------------------- ------------------- 1/2 [openai]\n",
      "   -------------------- ------------------- 1/2 [openai]\n",
      "   -------------------- ------------------- 1/2 [openai]\n",
      "   -------------------- ------------------- 1/2 [openai]\n",
      "   -------------------- ------------------- 1/2 [openai]\n",
      "   -------------------- ------------------- 1/2 [openai]\n",
      "   -------------------- ------------------- 1/2 [openai]\n",
      "   -------------------- ------------------- 1/2 [openai]\n",
      "   -------------------- ------------------- 1/2 [openai]\n",
      "   -------------------- ------------------- 1/2 [openai]\n",
      "   -------------------- ------------------- 1/2 [openai]\n",
      "   -------------------- ------------------- 1/2 [openai]\n",
      "   -------------------- ------------------- 1/2 [openai]\n",
      "   -------------------- ------------------- 1/2 [openai]\n",
      "   -------------------- ------------------- 1/2 [openai]\n",
      "   -------------------- ------------------- 1/2 [openai]\n",
      "   -------------------- ------------------- 1/2 [openai]\n",
      "   -------------------- ------------------- 1/2 [openai]\n",
      "   -------------------- ------------------- 1/2 [openai]\n",
      "   -------------------- ------------------- 1/2 [openai]\n",
      "   -------------------- ------------------- 1/2 [openai]\n",
      "   -------------------- ------------------- 1/2 [openai]\n",
      "   -------------------- ------------------- 1/2 [openai]\n",
      "   -------------------- ------------------- 1/2 [openai]\n",
      "   -------------------- ------------------- 1/2 [openai]\n",
      "   -------------------- ------------------- 1/2 [openai]\n",
      "   -------------------- ------------------- 1/2 [openai]\n",
      "   -------------------- ------------------- 1/2 [openai]\n",
      "   -------------------- ------------------- 1/2 [openai]\n",
      "   -------------------- ------------------- 1/2 [openai]\n",
      "   -------------------- ------------------- 1/2 [openai]\n",
      "   -------------------- ------------------- 1/2 [openai]\n",
      "   -------------------- ------------------- 1/2 [openai]\n",
      "   -------------------- ------------------- 1/2 [openai]\n",
      "   -------------------- ------------------- 1/2 [openai]\n",
      "   -------------------- ------------------- 1/2 [openai]\n",
      "   -------------------- ------------------- 1/2 [openai]\n",
      "   -------------------- ------------------- 1/2 [openai]\n",
      "   -------------------- ------------------- 1/2 [openai]\n",
      "   -------------------- ------------------- 1/2 [openai]\n",
      "   -------------------- ------------------- 1/2 [openai]\n",
      "   -------------------- ------------------- 1/2 [openai]\n",
      "   -------------------- ------------------- 1/2 [openai]\n",
      "   -------------------- ------------------- 1/2 [openai]\n",
      "   -------------------- ------------------- 1/2 [openai]\n",
      "   -------------------- ------------------- 1/2 [openai]\n",
      "   -------------------- ------------------- 1/2 [openai]\n",
      "   -------------------- ------------------- 1/2 [openai]\n",
      "   -------------------- ------------------- 1/2 [openai]\n",
      "   -------------------- ------------------- 1/2 [openai]\n",
      "   -------------------- ------------------- 1/2 [openai]\n",
      "   -------------------- ------------------- 1/2 [openai]\n",
      "   -------------------- ------------------- 1/2 [openai]\n",
      "   -------------------- ------------------- 1/2 [openai]\n",
      "   -------------------- ------------------- 1/2 [openai]\n",
      "   -------------------- ------------------- 1/2 [openai]\n",
      "   -------------------- ------------------- 1/2 [openai]\n",
      "   -------------------- ------------------- 1/2 [openai]\n",
      "   -------------------- ------------------- 1/2 [openai]\n",
      "   -------------------- ------------------- 1/2 [openai]\n",
      "   -------------------- ------------------- 1/2 [openai]\n",
      "   -------------------- ------------------- 1/2 [openai]\n",
      "   -------------------- ------------------- 1/2 [openai]\n",
      "   -------------------- ------------------- 1/2 [openai]\n",
      "   -------------------- ------------------- 1/2 [openai]\n",
      "   -------------------- ------------------- 1/2 [openai]\n",
      "   -------------------- ------------------- 1/2 [openai]\n",
      "   -------------------- ------------------- 1/2 [openai]\n",
      "   -------------------- ------------------- 1/2 [openai]\n",
      "   -------------------- ------------------- 1/2 [openai]\n",
      "   -------------------- ------------------- 1/2 [openai]\n",
      "   -------------------- ------------------- 1/2 [openai]\n",
      "   -------------------- ------------------- 1/2 [openai]\n",
      "   -------------------- ------------------- 1/2 [openai]\n",
      "   -------------------- ------------------- 1/2 [openai]\n",
      "   -------------------- ------------------- 1/2 [openai]\n",
      "   -------------------- ------------------- 1/2 [openai]\n",
      "   -------------------- ------------------- 1/2 [openai]\n",
      "   -------------------- ------------------- 1/2 [openai]\n",
      "   -------------------- ------------------- 1/2 [openai]\n",
      "   ---------------------------------------- 2/2 [openai]\n",
      "\n",
      "Successfully installed jiter-0.13.0 openai-2.17.0\n"
     ]
    }
   ],
   "source": [
    "!pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "cacc34c5-7f10-4cd9-8d0c-4b1aa917d18b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import json\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "49a0fa3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings = pd.read_csv('../data/The Movies Dataset/ratings_small.csv')\n",
    "\n",
    "movies = pd.read_csv('../data/The Movies Dataset/movies_metadata.csv', low_memory=False)\n",
    "keywords = pd.read_csv('../data/The Movies Dataset/keywords.csv')\n",
    "credits = pd.read_csv('../data/The Movies Dataset/credits.csv')\n",
    "\n",
    "links = pd.read_csv('../data/The Movies Dataset/links_small.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ca4e2aca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Удаляем повторяшки\n",
    "movies['id'] = pd.to_numeric(movies['id'], errors='coerce')\n",
    "movies = movies.dropna(subset=['id'])\n",
    "movies['id'] = movies['id'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f867c748",
   "metadata": {},
   "outputs": [],
   "source": [
    "movies = movies.drop_duplicates()\n",
    "links = links.drop_duplicates()\n",
    "ratings = ratings.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8f5f144d-8fee-40e6-9f79-0c2e41810adb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Добавляем tmdbI в ratings через файл links (id в movies_metadata)\n",
    "links = links.dropna(subset=['tmdbId'])\n",
    "links['tmdbId'] = links['tmdbId'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "704e9358-e63d-4f2e-a5a6-6f392fee05cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings = ratings[['userId', 'movieId', 'rating', 'timestamp']].merge(links[['tmdbId', 'movieId']], on='movieId', how='left')\n",
    "ratings = ratings.dropna(subset=['tmdbId'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "15f83a1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings['tmdbId'] = ratings['tmdbId'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c803ba18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Обработка жанров (нам нужны значения, а не целая запись словаря)\n",
    "def parse_json_field(text, key='name'):\n",
    "    try:\n",
    "        items = ast.literal_eval(text)\n",
    "        return [item[key] for item in items if key in item]\n",
    "    except (ValueError, SystemError):\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9baebb03-7106-40d9-b289-3d7b898959f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "movies['genres_list'] = movies['genres'].apply(lambda x: parse_json_field(x))\n",
    "movies['genres_str'] = movies['genres_list'].apply(lambda x: ', '.join(x) if x else 'Unknown')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2386d2ca-db79-45c9-a203-3c8df52b3ccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Также добавляем credits и keywords в movies_metadata\n",
    "credits['id'] = pd.to_numeric(credits['id'], errors='coerce')\n",
    "credits = credits.dropna(subset=['id'])\n",
    "credits['id'] = credits['id'].astype(int)\n",
    "\n",
    "keywords['id'] = pd.to_numeric(keywords['id'], errors='coerce')\n",
    "keywords = keywords.dropna(subset=['id'])\n",
    "keywords['id'] = keywords['id'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "db50a196-3159-4bf3-951f-5048ba61d5a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Важная фича для рекомендашки - режиссёр, но нам опять же нужно только значение (имя, фамилия)\n",
    "def get_director(crew_str):\n",
    "    try:\n",
    "        crew = ast.literal_eval(crew_str)\n",
    "        return next((m['name'] for m in crew if m['job'] == 'Director'), 'Unknown')\n",
    "    except:\n",
    "        return 'Unknown'\n",
    "    \n",
    "credits['director'] = credits['crew'].apply(get_director)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "da50ec76-2ae4-4566-8128-5111dcea920f",
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords['keywords_str'] = keywords['keywords'].apply(\n",
    "    lambda x: ', '.join(parse_json_field(x))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5d2e2483-03d8-4448-b752-c8ef48e7c3ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Актёрский каст\n",
    "def get_top_cast(cast_str, n=3):\n",
    "    try:\n",
    "        cast = ast.literal_eval(cast_str)\n",
    "        return ', '.join((c['name'] for c in cast[:n]))\n",
    "    except:\n",
    "        return 'Unknown'\n",
    "    \n",
    "credits['cast_str'] = credits['cast'].apply(get_top_cast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2b6b494d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Добавляем в фильмы инфу о режиссёре, касте и ключевые слова\n",
    "movies = movies.merge(credits[['id', 'director', 'cast_str']], on='id', how='left')\n",
    "movies = movies.merge(keywords[['id', 'keywords_str']], on='id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4883a5e5-b8c0-42f7-bd2d-c7778df7bcac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Обработка пропусков\n",
    "movies['overview'] = movies['overview'].fillna('No description available')\n",
    "movies['director'] = movies['director'].fillna('Unknown')\n",
    "movies['cast_str'] = movies['cast_str'].fillna('Unknown')\n",
    "movies['keywords_str'] = movies['keywords_str'].fillna('')\n",
    "movies['vote_count'] = movies['vote_count'].fillna(0)\n",
    "movies['vote_average'] = movies['vote_average'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "92bb08e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Нам не нужна вся дата, значение может иметь только год\n",
    "movies['year'] = pd.to_datetime(movies['release_date'], errors='coerce').dt.year\n",
    "movies['year'] = movies['year'].fillna(0).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dfb71b4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создаём текстовое описание для фильма\n",
    "def build_item_profile(row):\n",
    "    parts = [\n",
    "        f'\"{row['title']}\" ({row['year']})',\n",
    "        f'Genres: {row['genres_str']}',\n",
    "        f'Director: {row['director']}',\n",
    "        f'Cast: {row['cast_str']}',\n",
    "    ]\n",
    "    if row['keywords_str']:\n",
    "        parts.append(f'Keywords: {row['keywords_str']}')\n",
    "    parts.append(f'Plot: {row['overview'][:200]}')\n",
    "    parts.append(f'Ratings: {row['vote_average']}/10')\n",
    "\n",
    "    return ' | '.join(parts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "060d2e31-e072-4c3d-9ec5-8d947fcf9917",
   "metadata": {},
   "outputs": [],
   "source": [
    "movies['item_profile'] = movies.apply(build_item_profile, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "91fc7a1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Данные пользователя\n",
    "user_data = ratings.merge(\n",
    "    movies[['id', 'title', 'genres_str', 'director', 'year']],\n",
    "    left_on='tmdbId', right_on='id', how='inner'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "79e774a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_user_profile(user_id, group):\n",
    "    # Нас больше интересует недавняя активность\n",
    "    group = group.sort_values('timestamp')\n",
    "\n",
    "    # Последние 15 лайков (оценка 4 и выше)\n",
    "    liked = group[group['rating'] >= 4.0].tail(15)\n",
    "    # Последние 5 дизлайков\n",
    "    disliked = group[group['rating'] <= 2.0].tail(5)\n",
    "\n",
    "    # Достаём жанры из понравившихся фильмов\n",
    "    all_genres = []\n",
    "    for g in group[group['rating'] >= 4.0]['genres_str']:\n",
    "        all_genres.extend(g.split(', '))\n",
    "    from collections import Counter\n",
    "    top_genres = [g for d, _ in Counter(all_genres).most_common(5)]\n",
    "\n",
    "    # Достаём режиссёров\n",
    "    top_director = group[group['rating'] >= 4.0]['director'].value_counts().head(3).index.tolist()\n",
    "\n",
    "    profile = {\n",
    "        'user_id': user_id,\n",
    "        'avg_rating': round(group['rating'].mean(), 2),\n",
    "        'total_rating': len(group),\n",
    "        'top_genres': top_genres,\n",
    "        'top_director': top_director,\n",
    "        'liked_movies': liked[['title', 'year', 'rating']].to_dict('records'),\n",
    "        'disliked_movies': disliked[['title', 'year', 'rating']].to_dict('records'),\n",
    "    }\n",
    "\n",
    "    liked_str = '; '.join(\n",
    "        [f'{m['title']} ({m['rating']})' for m in profile['liked_movies']]\n",
    "    )\n",
    "    disliked_str = '; '.join(\n",
    "        [f'{m['title']} ({m['rating']})' for m in profile['disliked_movies']]\n",
    "    )\n",
    "\n",
    "    profile['text_profile'] = (\n",
    "        f'User {user_id}: '\n",
    "        f'Favorite genres: {', '.join(top_genres)}'\n",
    "        f'Favorite directors: {', '.join(top_director)}'\n",
    "        f'Average rating: {profile['avg_rating']}'\n",
    "        f'Recently liked: {liked_str}'\n",
    "        f'Recently disliked: {disliked_str}'\n",
    "    )\n",
    "\n",
    "    return profile\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b38429b2-11ce-49fc-87c6-af5e42e2069f",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_profiles = {}\n",
    "for uid, group in user_data.groupby('userId'):\n",
    "    user_profiles[uid] = build_user_profile(uid, group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c7de98e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Поиск похожих пользователей\n",
    "user_item_df = ratings.pivot(index='userId', columns='tmdbId', values='rating').fillna(0)\n",
    "user_sim_matrix = cosine_similarity(user_item_df.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6a4b552d-349e-469d-9745-6fde2cedfaf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_similar_users(user_id, top_k=5):\n",
    "   # косинусное расстояние\n",
    "    idx = list(user_item_df.index).index(user_id)\n",
    "    sims = user_sim_matrix[idx]\n",
    "    top_idxs = np.argsort(sims)[::-1][1:top_k+1]\n",
    "    return [(user_item_df.index[i], round(sims[i], 3)) for i in top_idxs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b1920240",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Теперь берём у похожего пользователя фильмы, чтобы посоветовать нашему\n",
    "tfidf = TfidfVectorizer(max_features=5000, stop_words='english')\n",
    "tfidf_matrix = tfidf.fit_transform(movies['item_profile'].fillna(''))\n",
    "\n",
    "def get_candidate_items(user_id, n_candidates=20):\n",
    "    watched = set(ratings[ratings['userId'] == user_id]['tmdbId'])\n",
    "    similar_users = get_similar_users(user_id, top_k=10)\n",
    "\n",
    "    candidates = set()\n",
    "    for sim_uid, _ in similar_users:\n",
    "        their_liked = ratings[(ratings['userId'] == sim_uid) & \n",
    "                              ratings['rating'] >= 4.0]['tmdbId']\n",
    "        candidates.update(their_liked.tolist())\n",
    "\n",
    "    candidates -= watched\n",
    "\n",
    "    candidates = list(candidates)[:n_candidates]\n",
    "    return candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d68c6bfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_recommendation_promt(target_user_id, candidate_movis_ids, similar_users):\n",
    "    # Профиль нашего пользователя\n",
    "    user_text = user_profiles[target_user_id]['text_profile']\n",
    "\n",
    "    # Фильмы, которые могут быть ему интересны\n",
    "    candidate_lines = []\n",
    "    for i, mid in enumerate(candidate_movis_ids):\n",
    "        row = movies[movies['id'] == mid].iloc[0]\n",
    "        candidate_lines.append(f'{i+1}. P{row['item_profile']}')\n",
    "    candidates_text = '\\n'.join(candidate_lines)\n",
    "\n",
    "    # Похожие ребята\n",
    "    similar_users_lines = []\n",
    "    for sim_uid, sim_score in similar_users:\n",
    "        sim_text = user_profiles[sim_uid]['text_profile']\n",
    "        similar_users_lines.append(\n",
    "            f'- {sim_text} (similarity: {sim_score})'\n",
    "        )\n",
    "    similar_text = '\\n'.join(similar_users_lines)\n",
    "\n",
    "    # Формирование промпта на основе схожести и интересов\n",
    "    promt = f\"\"\"\n",
    "        You are a movie recommendation expert. Your task is to recommend \n",
    "        movies and find similar users based on viewing preferences.\n",
    "\n",
    "        Target User: {user_text}\n",
    "\n",
    "        Candidates_text: {candidates_text}\n",
    "\n",
    "        Similar users (by rating patterns): {similar_text}\n",
    "\n",
    "        Instruction:\n",
    "        1. Analyze the target user's genre preferences, liked and disliked movies.\n",
    "        2. From the CANDIDATE MOVIES list, select the TOP 10 movies that best match \n",
    "        this user's taste. For each movie, explain why it fits.\n",
    "        3. From the SIMILAR USERS list, select the TOP 3 most similar users. \n",
    "        For each, explain what makes their taste similar to the target user.\n",
    "        4. Note that the user's most recently watched movies are the most indicative \n",
    "        of their current preferences.\n",
    "\n",
    "        Return ONLY valid JSON in this exact format:\n",
    "        {{\n",
    "        \"recommended_movies\": [\n",
    "            {{\"rank\": 1, \"title\": \"...\", \"reason\": \"...\"}},\n",
    "            ...\n",
    "        ],\n",
    "        \"similar_users\": [\n",
    "            {{\"user_id\": ..., \"similarity_reason\": \"...\"}},\n",
    "            ...\n",
    "        ]\n",
    "        }}\n",
    "    \"\"\"\n",
    "\n",
    "    return promt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6be5f2cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "api_key = os.getenv(\"PERPLEXITY_API_KEY\")\n",
    "\n",
    "client = OpenAI(\n",
    "    api_key=api_key,\n",
    "    base_url=\"https://api.perplexity.ai\"\n",
    ")\n",
    "\n",
    "def get_recommendations(user_id):\n",
    "    similar_users = get_similar_users(user_id, top_k=5)\n",
    "    candidate_ids = get_candidate_items(user_id, n_candidates=20)\n",
    "    \n",
    "    promt = build_recommendation_promt(user_id, candidate_ids, similar_users)\n",
    "\n",
    "    # LLM\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"sonar-pro\",\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": (\n",
    "                    \"You are a precise movie recommendation engine. \"\n",
    "                    \"Use ONLY the data provided. Do NOT search the web.\"\n",
    "                )\n",
    "            },\n",
    "            {\"role\": \"user\", \"content\": promt}\n",
    "        ],\n",
    "        temperature=0.2,\n",
    "        response_format={\n",
    "            \"type\": \"json_schema\",\n",
    "            \"json_schema\": {\n",
    "                \"name\": \"recommendations\",\n",
    "                \"schema\": {\n",
    "                    \"type\": \"object\",\n",
    "                    \"properties\": {\n",
    "                        \"recommended_movies\": {\n",
    "                            \"type\": \"array\",\n",
    "                            \"items\": {\n",
    "                                \"type\": \"object\",\n",
    "                                \"properties\": {\n",
    "                                    \"rank\": {\"type\": \"integer\"},\n",
    "                                    \"title\": {\"type\": \"string\"},\n",
    "                                    \"reason\": {\"type\": \"string\"}\n",
    "                                },\n",
    "                                \"required\": [\"rank\", \"title\", \"reason\"]\n",
    "                            }\n",
    "                        },\n",
    "                        \"similar_users\": {\n",
    "                            \"type\": \"array\",\n",
    "                            \"items\": {\n",
    "                                \"type\": \"object\",\n",
    "                                \"properties\": {\n",
    "                                    \"user_id\": {\"type\": \"integer\"},\n",
    "                                    \"similarity_reason\": {\"type\": \"string\"}\n",
    "                                },\n",
    "                                \"required\": [\"user_id\", \"similarity_reason\"]\n",
    "                            }\n",
    "                        }\n",
    "                    },\n",
    "                    \"required\": [\"recommended_movies\", \"similar_users\"]\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "\n",
    "    )\n",
    "    \n",
    "    # Парсим ответ в читабельный вид\n",
    "    result = json.loads(response.choices[0].message.content)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "991b6ed9-2090-4982-9a5c-12cc01b71928",
   "metadata": {},
   "outputs": [],
   "source": [
    "# получение рекоммендаций\n",
    "result = get_recommendations(user_id=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deb90af4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Рекомендуемые фильмы:\n",
      "  1. The Incredibles — Animated comedy-adventure similar to liked Kung Fu Panda 3, matching comedy genre preference and praised by similar users 509 and 461.\n",
      "  2. Napoleon Dynamite — Quirky comedy liked by similar user 509 (4.0), aligns with strong comedy preference and recent likes like Team America: World Police.\n",
      "  3. Little Miss Sunshine — Comedy-drama liked by similar user 388 (4.0), fits comedy focus and recent wedding comedy like Mike and Dave Need Wedding Dates.\n",
      "  4. Step Brothers — Absurd comedy liked by similar user 388 (4.0), matches recent likes like Father of the Bride and The Man Who Knew Too Little.\n",
      "  5. The Nice Guys — Comedy-crime film liked by similar user 73 (4.0), complements comedy genre and directors like Soderbergh/Fincher style.\n",
      "  6. WALL·E — Animated film similar to Kung Fu Panda per search results, fits family comedy and liked animated Kung Fu Panda 3.\n",
      "  7. Ratatouille — Animated comedy with animal protagonist, matches Kung Fu Panda style and comedy preference.\n",
      "  8. Shaun of the Dead — Comedy-horror liked by similar user 461 (4.0), though disliked by 509; fits comedy and recent horror like The Conjuring 2.\n",
      "  9. No Country for Old Men — Thriller by liked director Joel Coen (inferred from similar users), liked by 388 (4.0), aligns with Fincher/Soderbergh tastes.\n",
      "  10. The Dark Knight — Thriller liked by similar users 388 and 461 (4.0+), matches Fincher-style tension and recent likes like Jacob's Ladder.\n",
      "\n",
      "Похожие пользователи:\n",
      "  User 509 — Highest similarity (0.459); shares identical top comedy genre preference, likes quirky comedies like Napoleon Dynamite aligning with Team America and Man Who Knew Too Little.\n",
      "  User 73 — High similarity (0.459); shares director Steven Spielberg, likes comedies like The Nice Guys fitting recent comedy likes, despite horror focus.\n",
      "  User 388 — Strong similarity (0.437); shares Spielberg, likes comedies like Step Brothers and Little Miss Sunshine matching wedding comedies and overall comedy taste.\n"
     ]
    }
   ],
   "source": [
    "print(\"Рекомендуемые фильмы:\")\n",
    "for movie in result['recommended_movies']:\n",
    "    print(f\"  {movie['rank']}. {movie['title']} — {movie['reason']}\")\n",
    "\n",
    "print(\"Похожие пользователи:\")\n",
    "for user in result['similar_users']:\n",
    "    print(f\"  User {user['user_id']} — {user['similarity_reason']}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
