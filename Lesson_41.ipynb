{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import librosa\n",
        "import numpy as np\n",
        "import matplotlib\n",
        "import os\n",
        "import glob\n",
        "import random\n",
        "import soundfile as sf\n",
        "from pathlib import Path\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch.nn as nn\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import f1_score, classification_report\n",
        "from audiomentations import Compose, AddGaussianNoise, TimeStretch, PitchShift, Shift"
      ],
      "metadata": {
        "id": "lG79KRKMlKmw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_fix_audio(path, target_sr=16000, target_len_sec=3.0):\n",
        "    y, sr = librosa.load(path, sr=target_sr, mono=True)\n",
        "\n",
        "    n_target = int(target_sr * target_len_sec)\n",
        "\n",
        "    if len(y) < n_target:\n",
        "        y = np.pad(y, (0, n_target - len(y)), mode='constant')\n",
        "    else:\n",
        "        y = y[:n_target]\n",
        "\n",
        "    return y"
      ],
      "metadata": {
        "id": "4UIqPiEDuqiI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# функуия для разбиения данных\n",
        "def split_dataset(root_dir, test_size=0.15, val_size=0.15, min_per_class=2):\n",
        "    root_path = Path(root_dir)\n",
        "    files = list(root_path.rglob(\"*.wav\"))\n",
        "    files = [str(p) for p in files]\n",
        "    # files = glob.glob(os.path.join(root_dir, \"**/*.wav\"), recursive=True)\n",
        "    labels = [1 if \"barbie\" in f else 0 for f in files]\n",
        "\n",
        "    n_barbie = sum(labels)\n",
        "    n_puppy = len(labels) - n_barbie\n",
        "    print(f\"Всего: {len(files)} файлов (barbie={n_barbie}, puppy={n_puppy})\")\n",
        "\n",
        "    X_train, X_temp, y_train, y_temp = train_test_split(\n",
        "        files, labels, test_size=test_size + val_size, stratify=labels, random_state=42\n",
        "    )\n",
        "\n",
        "    rel_val = val_size / (test_size + val_size)\n",
        "\n",
        "    X_val, X_test, y_val, y_test = train_test_split(\n",
        "        X_temp, y_temp, test_size=rel_val, stratify=y_temp, random_state=42\n",
        "    )\n",
        "\n",
        "    return (X_train, y_train), (X_val, y_val), (X_test, y_test)\n"
      ],
      "metadata": {
        "id": "cxfC43wDl-s5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_logmel(y, sr=16000, n_mels=64):\n",
        "    mel = librosa.feature.melspectrogram(y=y, sr=sr, n_mels=n_mels)\n",
        "    logmel = librosa.power_to_db(mel, ref=np.max)\n",
        "    return logmel"
      ],
      "metadata": {
        "id": "2UZebnn6oKDp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "augment_transform = Compose([\n",
        "    AddGaussianNoise(min_amplitude=0.001, max_amplitude=0.015, p=0.5),\n",
        "    TimeStretch(min_rate=0.8, max_rate=1.25, p=0.5),\n",
        "    PitchShift(min_semitones=-2, max_semitones=2, p=0.5),\n",
        "    Shift(p=0.5),\n",
        "])\n",
        "\n",
        "def load_and_augment(path, sr=16000):\n",
        "    y, _ = librosa.load(path, sr=sr)\n",
        "\n",
        "    y_aug = augment_transform(samples=y, sample_rate=sr)\n",
        "    return y_aug\n"
      ],
      "metadata": {
        "id": "Dpv-OIgioVd5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class AudioDataset(Dataset):\n",
        "    def __init__(self, files, labels, feature_type=\"logmel\", augment=False):\n",
        "        self.files = files\n",
        "        self.labels = labels\n",
        "        self.feature_type = feature_type\n",
        "        self.augment = augment\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.files)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        path = self.files[idx]\n",
        "        label = self.labels[idx]\n",
        "\n",
        "        y = load_fix_audio(path)\n",
        "\n",
        "        if self.augment:\n",
        "            y = augment_transform(samples=y, sample_rate=16000)\n",
        "\n",
        "        if self.feature_type == \"logmel\":\n",
        "            feat = extract_logmel(y)\n",
        "        # elif self.feature_type == \"cqt\":\n",
        "        #     feat = extract_cqt(path)\n",
        "        # elif self.feature_type == \"mfccdelta\":\n",
        "        #     feat = extract_mfcc_delta(path)\n",
        "        else:\n",
        "            raise ValueError(\"Unknown feature type\")\n",
        "\n",
        "        feat = (feat - feat.mean()) / (feat.std() + 1e-8)\n",
        "        feat = torch.tensor(feat, dtype=torch.float32).unsqueeze(0)\n",
        "\n",
        "        return feat, torch.tensor(label, dtype=torch.long)\n"
      ],
      "metadata": {
        "id": "JMd7qkOxpIyS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MLP(nn.Module):\n",
        "    def __init__(self, input_shape, hidden_size=256):\n",
        "        super().__init__()\n",
        "\n",
        "        freq, time = input_shape\n",
        "        input_dim = freq * time\n",
        "\n",
        "        self.model = nn.Sequential(\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(input_dim, hidden_size),\n",
        "            nn.BatchNorm1d(hidden_size),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.3),\n",
        "\n",
        "            nn.Linear(hidden_size, hidden_size),\n",
        "            nn.BatchNorm1d(hidden_size),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.3),\n",
        "\n",
        "            nn.Linear(hidden_size, 2)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.model(x)"
      ],
      "metadata": {
        "id": "4oj4TBlrq0EX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "root_dir = \"data\"\n",
        "(train_files, train_labels), (val_files, val_labels), (test_files, test_labels) = split_dataset(root_dir)\n",
        "\n",
        "feature_type = \"logmel\"\n",
        "\n",
        "train_ds = AudioDataset(train_files, train_labels, feature_type=feature_type, augment=True)\n",
        "val_ds   = AudioDataset(val_files,   val_labels,   feature_type=feature_type, augment=False)\n",
        "test_ds  = AudioDataset(test_files,  test_labels,  feature_type=feature_type, augment=False)\n",
        "\n",
        "train_dl = DataLoader(train_ds, batch_size=16, shuffle=True)\n",
        "val_dl   = DataLoader(val_ds,   batch_size=16, shuffle=False)\n",
        "test_dl  = DataLoader(test_ds,  batch_size=16, shuffle=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ai8cKzxFtaPV",
        "outputId": "4a8d12aa-73b8-430c-9071-015f72d3de43"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Всего: 98 файлов (barbie=50, puppy=48)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(train_ds)"
      ],
      "metadata": {
        "id": "MbRtVNT68sPo",
        "outputId": "d7326cbd-14e5-45ee-d139-34d8b610edcd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "68"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sample_x, _ = train_ds[0]\n",
        "input_shape = sample_x.squeeze(0).shape\n",
        "input_shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PlXY0oVstzmq",
        "outputId": "2955b9be-3431-45b4-c6e6-feec962ccd96"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([64, 94])"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = MLP(input_shape=input_shape, hidden_size=256).to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)"
      ],
      "metadata": {
        "id": "TPpqCjist6lu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def run_epoch(model, dataloader, optimizer=None):\n",
        "    if optimizer is None:\n",
        "        model.eval()\n",
        "    else:\n",
        "        model.train()\n",
        "\n",
        "    total_loss = 0.0\n",
        "    total_correct = 0\n",
        "    total_samples = 0\n",
        "\n",
        "    for x, y in dataloader:\n",
        "        x = x.to(device)\n",
        "        y = y.to(device)\n",
        "\n",
        "        if optimizer is not None:\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "        logits = model(x)\n",
        "        loss = criterion(logits, y)\n",
        "\n",
        "        if optimizer is not None:\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "        total_loss += loss.item() * y.size(0)\n",
        "        preds = logits.argmax(dim=1)\n",
        "        total_correct += (preds == y).sum().item()\n",
        "        total_samples += y.size(0)\n",
        "\n",
        "    avg_loss = total_loss / total_samples\n",
        "    avg_acc = total_correct / total_samples\n",
        "    return avg_loss, avg_acc"
      ],
      "metadata": {
        "id": "TedKUy_zuDtQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 15\n",
        "\n",
        "for epoch in range(1, num_epochs + 1):\n",
        "    train_loss, train_acc = run_epoch(model, train_dl, optimizer)\n",
        "    val_loss, val_acc = run_epoch(model, val_dl, optimizer=None)\n",
        "\n",
        "    print(\n",
        "        f\"Epoch {epoch:02d} | \"\n",
        "        f\"train_loss={train_loss:.4f}, train_acc={train_acc:.3f} | \"\n",
        "        f\"val_loss={val_loss:.4f}, val_acc={val_acc:.3f}\"\n",
        "    )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TObUsGEIuKam",
        "outputId": "565477a0-2e81-4754-fa96-7a88bb510742"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 01 | train_loss=0.6010, train_acc=0.647 | val_loss=0.6160, val_acc=0.600\n",
            "Epoch 02 | train_loss=0.7575, train_acc=0.500 | val_loss=0.5863, val_acc=0.667\n",
            "Epoch 03 | train_loss=0.7216, train_acc=0.574 | val_loss=0.6048, val_acc=0.600\n",
            "Epoch 04 | train_loss=0.6836, train_acc=0.603 | val_loss=0.6602, val_acc=0.533\n",
            "Epoch 05 | train_loss=0.7230, train_acc=0.662 | val_loss=0.7342, val_acc=0.533\n",
            "Epoch 06 | train_loss=0.7144, train_acc=0.559 | val_loss=0.7167, val_acc=0.467\n",
            "Epoch 07 | train_loss=0.7191, train_acc=0.632 | val_loss=0.6645, val_acc=0.600\n",
            "Epoch 08 | train_loss=0.6779, train_acc=0.618 | val_loss=0.6582, val_acc=0.667\n",
            "Epoch 09 | train_loss=0.7070, train_acc=0.529 | val_loss=0.6516, val_acc=0.533\n",
            "Epoch 10 | train_loss=0.6929, train_acc=0.662 | val_loss=0.6401, val_acc=0.667\n",
            "Epoch 11 | train_loss=0.6730, train_acc=0.618 | val_loss=0.6364, val_acc=0.600\n",
            "Epoch 12 | train_loss=0.6510, train_acc=0.691 | val_loss=0.6299, val_acc=0.600\n",
            "Epoch 13 | train_loss=0.6400, train_acc=0.632 | val_loss=0.6362, val_acc=0.533\n",
            "Epoch 14 | train_loss=0.6005, train_acc=0.647 | val_loss=0.7003, val_acc=0.533\n",
            "Epoch 15 | train_loss=0.5699, train_acc=0.735 | val_loss=0.7384, val_acc=0.533\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss, test_acc = run_epoch(model, test_dl, optimizer=None)\n",
        "print(f\"\\nTest: loss={test_loss:.4f}, acc={test_acc:.3f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rDx-fJJB05tE",
        "outputId": "f25ecbca-a971-4b58-ce6c-b8e2ff537268"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test: loss=0.6481, acc=0.467\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def predict(model, dataloader, device):\n",
        "    model.eval()\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "    all_probs = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for x, y in dataloader:\n",
        "            x = x.to(device)\n",
        "            logits = model(x)\n",
        "            probs = torch.softmax(logits, dim=1)\n",
        "            preds = logits.argmax(dim=1)\n",
        "\n",
        "            all_preds.extend(preds.cpu().numpy())\n",
        "            all_labels.extend(y.numpy())\n",
        "            all_probs.extend(probs.cpu().numpy())\n",
        "\n",
        "    return np.array(all_preds), np.array(all_labels), np.array(all_probs)\n",
        "\n",
        "test_preds, test_labels, test_probs = predict(model, test_dl, device)"
      ],
      "metadata": {
        "id": "mQmytJpt1guX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Распределение в тестовой выборке:\")\n",
        "print(f\"  True labels:  unique={np.unique(test_labels)}, counts={np.bincount(test_labels)}\")\n",
        "print(f\"  Predictions:  unique={np.unique(test_preds)}, counts={np.bincount(test_preds)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hCFqnWAM20Ex",
        "outputId": "226581d9-7151-47ad-b5b9-cf88b2f7cae2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Распределение в тестовой выборке:\n",
            "  True labels:  unique=[0 1], counts=[8 7]\n",
            "  Predictions:  unique=[0 1], counts=[6 9]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class_names = ['puppy', 'barbie']\n",
        "\n",
        "print(classification_report(\n",
        "    test_labels,\n",
        "    test_preds,\n",
        "    labels=[0, 1],\n",
        "    target_names=class_names,\n",
        "    zero_division=0\n",
        "))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nq_8Y5BN2-hf",
        "outputId": "79b65a19-7e04-4be8-8699-f65731325d81"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "       puppy       0.00      0.00      0.00         0\n",
            "      barbie       1.00      1.00      1.00        15\n",
            "\n",
            "    accuracy                           1.00        15\n",
            "   macro avg       0.50      0.50      0.50        15\n",
            "weighted avg       1.00      1.00      1.00        15\n",
            "\n"
          ]
        }
      ]
    }
  ]
}